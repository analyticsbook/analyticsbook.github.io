<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Chapter 4. Resonance: Bootstrap &amp; Random Forests | Data Analytics: A Small Data Approach" />
<meta property="og:type" content="book" />


<meta property="og:description" content="This book is suitable for an introductory course of data analytics to help students understand some main statistical learning models, such as linear regression, logistic regression, tree models and random forests, ensemble learning, sparse learning, principal component analysis, kernel methods including the support vector machine and kernel regression, etc. Data science practice is a process that should be told as a story, rather than a one-time implementation of one single model. This process is a main focus of this book, with many course materials about exploratory data analysis, residual analysis, and flowcharts to develop and validate models and data pipelines." />


<meta name="author" content="Shuai Huang &amp; Houtao Deng" />

<meta name="date" content="2021-12-03" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="This book is suitable for an introductory course of data analytics to help students understand some main statistical learning models, such as linear regression, logistic regression, tree models and random forests, ensemble learning, sparse learning, principal component analysis, kernel methods including the support vector machine and kernel regression, etc. Data science practice is a process that should be told as a story, rather than a one-time implementation of one single model. This process is a main focus of this book, with many course materials about exploratory data analysis, residual analysis, and flowcharts to develop and validate models and data pipelines.">

<title>Chapter 4. Resonance: Bootstrap &amp; Random Forests | Data Analytics: A Small Data Approach</title>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<meta name="description" content="My awesome presentation"/>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-194836795-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-194836795-1');
</script>
<script src="https://use.typekit.net/ajy6rnl.js"></script>
<script>try{Typekit.load({ async: true });}catch(e){}</script>
<!-- <link rel="stylesheet" href="css/normalize.css"> -->
<!-- <link rel="stylesheet" href="css/envisioned.css"/> -->
<link rel="stylesheet" href="css/tablesaw-stackonly.css"/>
<link rel="stylesheet" href="css/nudge.css"/>
<link rel="stylesheet" href="css/sourcesans.css"/>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>




</head>

<body>

<!--bookdown:toc:start-->

<nav class="pushy pushy-left" id="TOC">
<ul>
<li><a href="#cover">Cover</a></li>
<li><a href="#preface">Preface</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
<li><a href="#chapter-1.-introduction">Chapter 1. Introduction</a></li>
<li><a href="#chapter-2.-abstraction-regression-tree-models">Chapter 2. Abstraction: Regression &amp; Tree Models</a></li>
<li><a href="#chapter-3.-recognition-logistic-regression-ranking">Chapter 3. Recognition: Logistic Regression &amp; Ranking</a></li>
<li><a href="#chapter-4.-resonance-bootstrap-random-forests">Chapter 4. Resonance: Bootstrap &amp; Random Forests</a></li>
<li><a href="#chapter-5.-learning-i-cross-validation-oob">Chapter 5. Learning (I): Cross-validation &amp; OOB</a></li>
<li><a href="#chapter-6.-diagnosis-residuals-heterogeneity">Chapter 6. Diagnosis: Residuals &amp; Heterogeneity</a></li>
<li><a href="#chapter-7.-learning-ii-svm-ensemble-learning">Chapter 7. Learning (II): SVM &amp; Ensemble Learning</a></li>
<li><a href="#chapter-8.-scalability-lasso-pca">Chapter 8. Scalability: LASSO &amp; PCA</a></li>
<li><a href="#chapter-9.-pragmatism-experience-experimental">Chapter 9. Pragmatism: Experience &amp; Experimental</a></li>
<li><a href="#chapter-10.-synthesis-architecture-pipeline">Chapter 10. Synthesis: Architecture &amp; Pipeline</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#appendix-a-brief-review-of-background-knowledge">Appendix: A Brief Review of Background Knowledge</a></li>
</ul>
</nav>

<!--bookdown:toc:end-->

<div class="menu-btn"><h3>☰ Menu</h3></div>

<div class="site-overlay"></div>


<div class="row">
<div class="col-sm-12">

<nav class="pushy pushy-left" id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="preface.html#preface">Preface</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li><a href="chapter-1.-introduction.html#chapter-1.-introduction">Chapter 1. Introduction</a></li>
<li><a href="chapter-2.-abstraction-regression-tree-models.html#chapter-2.-abstraction-regression-tree-models">Chapter 2. Abstraction: Regression &amp; Tree Models</a></li>
<li><a href="chapter-3.-recognition-logistic-regression-ranking.html#chapter-3.-recognition-logistic-regression-ranking">Chapter 3. Recognition: Logistic Regression &amp; Ranking</a></li>
<li><a href="chapter-4.-resonance-bootstrap-random-forests.html#chapter-4.-resonance-bootstrap-random-forests">Chapter 4. Resonance: Bootstrap &amp; Random Forests</a></li>
<li><a href="chapter-5.-learning-i-cross-validation-oob.html#chapter-5.-learning-i-cross-validation-oob">Chapter 5. Learning (I): Cross-validation &amp; OOB</a></li>
<li><a href="chapter-6.-diagnosis-residuals-heterogeneity.html#chapter-6.-diagnosis-residuals-heterogeneity">Chapter 6. Diagnosis: Residuals &amp; Heterogeneity</a></li>
<li><a href="chapter-7.-learning-ii-svm-ensemble-learning.html#chapter-7.-learning-ii-svm-ensemble-learning">Chapter 7. Learning (II): SVM &amp; Ensemble Learning</a></li>
<li><a href="chapter-8.-scalability-lasso-pca.html#chapter-8.-scalability-lasso-pca">Chapter 8. Scalability: LASSO &amp; PCA</a></li>
<li><a href="chapter-9.-pragmatism-experience-experimental.html#chapter-9.-pragmatism-experience-experimental">Chapter 9. Pragmatism: Experience &amp; Experimental</a></li>
<li><a href="chapter-10.-synthesis-architecture-pipeline.html#chapter-10.-synthesis-architecture-pipeline">Chapter 10. Synthesis: Architecture &amp; Pipeline</a></li>
<li><a href="conclusion.html#conclusion">Conclusion</a></li>
<li><a href="appendix-a-brief-review-of-background-knowledge.html#appendix-a-brief-review-of-background-knowledge">Appendix: A Brief Review of Background Knowledge</a></li>
</ul>
</nav>

</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="chapter-4.-resonance-bootstrap-random-forests" class="section level1 unnumbered">
<h1>Chapter 4. Resonance: Bootstrap &amp; Random Forests</h1>
<div id="overview-2" class="section level2 unnumbered">
<h2>Overview</h2>
<p>Chapter 4 is about <em>Resonance</em>. It is how we work with computers to exploit its remarkable power in conducting iterations and repetitive tasks which human beings find burdensome to do. This capacity of computers enables applications of modern optimization algorithms which underlie many data analytics models. This capacity also makes it realistic to use statistical techniques that don’t require analytic tractability.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-iteration-hend"></span>
<img src="graphics/4_iteration_hend.png" alt="Iterations from a pendulum" width="60%"  />
<!--
<p class="caption marginnote">-->Figure 53: Iterations from a pendulum<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-iteration-spiral"></span>
<img src="graphics/4_iteration_spiral.png" alt="Iterations that form a spiral" width="60%"  />
<!--
<p class="caption marginnote">-->Figure 54: Iterations that form a spiral<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>Decomposing a computational task into repetitive subtasks needs skillful design. The subtasks should be identical in their mathematical forms, so if they differ from each other they only differ in their specific <em>parametric</em> configurations. A subtask should also be easy to solve, and sometimes there is even closed-form solution. These subtasks may or may not be carried out in a sequential manner, but as a whole, they <em>move things forward</em>—solving a problem. Not all repetitions move things forward, e.g., two types of repetitions are shown in Figures <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-iteration-hend">53</a> and <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-iteration-spiral">54</a>.</p>
<p>Comparing with the <em>divide-and-conquer</em> that is more of a spatial nature, here, repetition is more of a temporal nature, and effective designs of repetitions need the power of <em>resonance</em> between the repetitions. If they are carried out in a sequential manner, they do not depend on each other logically like in a deduction sequence; and if one subtask is only solved suboptimally, as a whole they move forward towards an optimal solution.</p>
<p>A particular invention that has played a critical role in many data analytic applications is the <strong>Bootstrap</strong>. Building on the idea of Bootstrap, Random Forest was invented in 2001,<label for="tufte-sn-79" class="margin-toggle sidenote-number">79</label><input type="checkbox" id="tufte-sn-79" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">79</span> Breiman, L., <em>Random Forests.</em> Machine Learning, Volume 45, Issue 1, Pages 5-32, 2001.</span> after that came countless <strong>Ensemble Learning</strong> methods<label for="tufte-sn-80" class="margin-toggle sidenote-number">80</label><input type="checkbox" id="tufte-sn-80" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">80</span> See <strong>Chapter 7</strong>.</span>.</p>
<div style="page-break-after: always;"></div>
</div>
<div id="how-bootstrap-works" class="section level2 unnumbered">
<h2>How bootstrap works</h2>
<div id="rationale-and-formulation-5" class="section level3 unnumbered">
<h3>Rationale and formulation</h3>
<p>There are multiple perspectives to look at Bootstrap. One perspective that has been well studied in the seminar book<label for="tufte-sn-81" class="margin-toggle sidenote-number">81</label><input type="checkbox" id="tufte-sn-81" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">81</span> Efron, B. and Tibshirani, R.J., * An Introduction to the Bootstrap.* Chapman &amp; Hall/CRC, 1993.</span> is to treat Bootstrap as a simulation of the <em>sampling process</em>. As we know, sampling refers to the idea that we could draw samples again and again from the same population. Many statistical techniques make sense only when we put them in the framework of sampling<label for="tufte-sn-82" class="margin-toggle sidenote-number">82</label><input type="checkbox" id="tufte-sn-82" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">82</span> When statistics gained its scientific foundation and a modern appeal, there was also the rise of <em>mass production</em> that introduced human beings into a mechanical world populated with endless repetitive movements of machines and processes, as dramatized in Charlie Chaplin’s movies.</span>. For example, in hypothesis testing, when the Type 1 Error (a.k.a., the <span class="math inline">\(\alpha\)</span>) is set to be <span class="math inline">\(0.05\)</span>, it means that if we are able to repeat for multiple times the data collection, computation of statistics, and hypothesis testing, on average we will reject the null hypothesis <span class="math inline">\(5\%\)</span> of the times even when the null hypothesis is true.</p>
<p>For many statistical models, the analytic <em>tractability</em> of the sampling process lays the foundation to study their behavior and performance. When there were no computers, analytical tractability had been (and still is) one main factor that determines the “fate” of a statistical model—i.e., if we haven’t found an analytical tractable formulation to study the model considering its sampling process, it is hard to convince statisticians that the model is valid<label for="tufte-sn-83" class="margin-toggle sidenote-number">83</label><input type="checkbox" id="tufte-sn-83" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">83</span> E.g., without the possibility (even the possibility is probably only <em>theoretical</em>) of infinite repetition of the same process, the concept <span class="math inline">\(\alpha\)</span> in hypothesis testing will lose its ground of being something tangible.</span>. Nonetheless, there have been good statistical models that have no rigorous mathematical formulations, yet they are effective in applications. It may take years for us to find a mathematical framework to establish these models as rigorous approaches.</p>
<p>As a remedy, Bootstrap exploits the power of computers to simulate the sampling process. Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-1">55</a> provides a simple illustration of its idea. The input of a Bootstrap algorithm is a dataset, which provides a <em>representation</em> of the underlying population. As the dataset is considered to be an representational <em>equivalent</em> of the underlying population, <em>sampling from the underlying population</em> could be approximated by <em>resampling from the dataset</em>. As shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-1">55</a>, we could generate any number of Bootstrapped datasets by randomly drawing samples (with or without replacement, both have been useful) from the dataset. The idea is simple and effective.</p>
<p></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:f4-1"></span>
<p class="caption marginnote shownote">
Figure 55: A demonstration of the Bootstrap process
</p>
<img src="graphics/4_1.png" alt="A demonstration of the Bootstrap process" width="60%"  />
</div>
<p></p>
<p><em>The conceptual power of Bootstrap.</em> A good model has a concrete procedure of operations. That is <em>what it does</em>. There is also a conceptual-level perspective that concerns a model regarding <em>what it is</em>.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-samplingprocess"></span>
<img src="graphics/4_samplingprocess.png" alt="A demonstration of the sampling process" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 56: A demonstration of the sampling process<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>A sampling process is conventionally—or conveniently—conceived as a static snapshot, as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-samplingprocess">56</a>. The data points are pictured as silhouettes of apples, to highlight the psychological tendency we all share that we too often focus on the samples (the fruit) rather than the sampling process (the tree). This view is not entirely wrong, but it is a reduced view and it is easy for this fact to slip below the level of consciousness. We often take the apples as an absolute fact and forget that they are only historic coincidence: they are a <em>representation</em> of the apple tree (here, corresponds to the concept <em>population</em>); they themselves are not the apple tree.</p>
<p></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:f4-samplingprocess2"></span>
<p class="caption marginnote shownote">
Figure 57: A demonstration of the dynamic view of Bootstrap. The tree is drawn using <a href="http://mwskirpan.com/FractalTree/">http://mwskirpan.com/FractalTree/</a>.
</p>
<img src="graphics/4_samplingprocess_tree.png" alt="A demonstration of the dynamic view of Bootstrap. The tree is drawn using [http://mwskirpan.com/FractalTree/](http://mwskirpan.com/FractalTree/)." width="80%"  />
</div>
<p></p>
<p>The Bootstrap starts from what we have forgotten. Not to study an apple as an apple, it studies the process of how an apple is created, the process of apple<em>-ing</em>. Bearing this objective in mind, an apple is no longer empirical, now it is a <em>general</em> apple. It bears the genetics of apple that is shared by all apples and conceives the possibility of an apple tree. This is the power of the Bootstrap on the conceptual level. As illustrated in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-samplingprocess2">57</a>, it now animates the static snapshot shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-samplingprocess">56</a> and recovers the dynamic process. It creates resonance among the snapshots, and the resonance completes the big picture and enlarges our conceptual view of the problem.</p>
</div>
<div id="theory-and-method-3" class="section level3 unnumbered">
<h3>Theory and method</h3>
<p>Let’s consider the estimator of the mean of a normal population. A random variable <span class="math inline">\(X\)</span> follows a normal distribution, i.e., <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right)\)</span>. For simplicity, let’s assume that we have known the variance <span class="math inline">\(\sigma^{2}\)</span>. We want to estimate the mean <span class="math inline">\(\mu\)</span>. What we need to do is to randomly draw a few samples from the distribution. Denote these samples as <span class="math inline">\(x_{1}, x_{2}, \ldots, x_{N}\)</span>. To estimate <span class="math inline">\(\mu\)</span> , it seems natural to use the average of the samples, denoted as <span class="math inline">\(\overline{x}=\frac{1}{N} \sum_{n=1}^{N} x_{i}\)</span>. We use <span class="math inline">\(\overline{x}\)</span> as an estimator of <span class="math inline">\(\mu\)</span>, i.e., <span class="math inline">\(\hat{\mu}=\overline{x}\)</span>.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-two-sampling-process"></span>
<img src="graphics/4_two_sampling_process.png" alt="A sampling process that concerns $x$ (upper) and an enlarged view of the sampling process that concerns both $x$ and $\hat{\mu}$ (bottom)" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 58: A sampling process that concerns <span class="math inline">\(x\)</span> (upper) and an enlarged view of the sampling process that concerns both <span class="math inline">\(x\)</span> and <span class="math inline">\(\hat{\mu}\)</span> (bottom)<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>A question arises, how good is <span class="math inline">\(\overline{x}\)</span> to be an estimator of <span class="math inline">\(\mu\)</span>?</p>
<p>Obviously, if <span class="math inline">\(\overline{x}\)</span> is numerically close to <span class="math inline">\(\mu\)</span>, it is a good estimator. The problem is, for a particular dataset, we don’t know what is <span class="math inline">\(\mu\)</span>. And even if we know <span class="math inline">\(\mu\)</span>, we need to have criteria to tell us how close is close enough. On top of all these considerations, common sense tells us that <span class="math inline">\(\overline{x}\)</span> itself is a random variable that is subject to uncertainty. To evaluate this uncertainty and get a general sense of how closely <span class="math inline">\(\overline{x}\)</span> estimates <span class="math inline">\(\mu\)</span>, a brute-force approach is to repeat the physical experiment many times. But this is not necessary. In this particular problem, where <span class="math inline">\(X\)</span> follows a normal distribution, we could circumvent the physical burden (i.e., of repeating the experiments) via mathematical derivation. Since <span class="math inline">\(X\)</span> follows a normal distribution, we could derive that <span class="math inline">\(\overline{x}\)</span> is another normal distribution, i.e., <span class="math inline">\(\overline{x} \sim N\left(\mu, \sigma^{2} / N\right)\)</span>. Then we know that <span class="math inline">\(\overline{x}\)</span> is an unbiased estimator, since <span class="math inline">\(E(\overline{x})=\mu\)</span>. Also, we know that the larger the sample size, the better the estimation of <span class="math inline">\(\mu\)</span> by <span class="math inline">\(\overline{x}\)</span>, since the variance of the estimator is <span class="math inline">\(\sigma^{2} / N\)</span>.<label for="tufte-sn-84" class="margin-toggle sidenote-number">84</label><input type="checkbox" id="tufte-sn-84" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">84</span> In this case, the sampling process includes (1) drawing samples from the distribution; and (2) estimating <span class="math inline">\(\mu\)</span> using <span class="math inline">\(\overline{x}\)</span>. Illustration is shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-two-sampling-process">58</a>. The <em>sampling process</em> is a flexible concept, depending on what variables are under study.</span></p>
<p></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:f4-2"></span>
<p class="caption marginnote shownote">
Figure 59: The (nonparametric) Bootstrap scheme to computationally evaluate the sampling distribution of <span class="math inline">\(\overline{x}\)</span>
</p>
<img src="graphics/4_2.png" alt="The (nonparametric) Bootstrap scheme to computationally evaluate the sampling distribution of $\overline{x}$" width="80%"  />
</div>
<p></p>
<p><em>When Bootstrap is needed.</em> Apparently, knowing the analytic form of <span class="math inline">\(\overline{x}\)</span> is the key in the example shown above to circumvent the physical need of sampling. And the analytic tractability originates from the condition that <span class="math inline">\(X\)</span> follows normal distribution. For many other estimators that we found analytically intractable, Bootstrap provides a computational remedy that enables us to investigate their properties, because it <em>computationally</em> mimics the physical sampling process.</p>
<p>For example, while the distribution of <span class="math inline">\(X\)</span> is unknown, we could follow the Bootstrap scheme illustrated in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a> to evaluate the sampling distribution of <span class="math inline">\(\overline{x}\)</span>. For any bootstrapped dataset, we can calculate the <span class="math inline">\(\overline{x}\)</span> and obtain a “sample” of <span class="math inline">\(\overline{x}\)</span>, denoted as <span class="math inline">\(\overline{x}_i\)</span>. Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a> only illustrates three cases, while in practice usually thousands of bootstrapped datasets are drawn. After we have the “samples” of <span class="math inline">\(\overline{x}\)</span>, we can draw the distribution of <span class="math inline">\(\overline{x}\)</span> and present it as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a>. Although we don’t know the distribution’s analytic form, we have its numerical representation stored in a computer.</p>
<p>The Bootstrap scheme illustrated in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a> is called <em>nonparametric</em> Bootstrap, since no <em>parametric</em> model is used to mediate the process<label for="tufte-sn-85" class="margin-toggle sidenote-number">85</label><input type="checkbox" id="tufte-sn-85" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">85</span> Put simply, a parametric model is a model with an explicit mathematical form that is calibrated by parameters.</span>. This is not the only way through which we can conduct Bootstrap. For example, a parametric Bootstrap scheme is illustrated in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-3">60</a> to perform the same task, i.e., to study the sampling distribution of <span class="math inline">\(\overline{x}\)</span>. The difference between the nonparametric Bootstrap scheme in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a> and the parametric Bootstrap scheme in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-3">60</a> is that, when generating new samples, the nonparametric Bootstrap uses the original dataset as the representation of the underlying population, while the parametric Bootstrap uses a fitted distribution model.</p>
<p></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:f4-3"></span>
<p class="caption marginnote shownote">
Figure 60:  The (parametric) Bootstrap scheme to computationally evaluate the sampling distribution of <span class="math inline">\(\overline{x}\)</span>
</p>
<img src="graphics/4_3.png" alt=" The (parametric) Bootstrap scheme to computationally evaluate the sampling distribution of $\overline{x}$" width="80%"  />
</div>
<p></p>
<p><em>Bootstrap for regression model.</em> We show another example about how Bootstrap could be used. In <strong>Chapter 2</strong>, we showed that we can derive the explicit distribution of the estimated regression parameters<label for="tufte-sn-86" class="margin-toggle sidenote-number">86</label><input type="checkbox" id="tufte-sn-86" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">86</span> Recall that, to derive this distribution, a few assumptions are needed: the Gaussian assumption of the error term, and the linear assumptions between predictors and outcome variable.</span>. Here, we introduce another approach, based on the idea of Bootstrap, to <em>compute</em> an empirical distribution of the estimated regression parameters.</p>
<p>The first challenge we encounter is the ambiguity of “population” here. Unlike in the parameter estimation examples shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a>, here, a regression model involves three entities, the predictors <span class="math inline">\(\boldsymbol{x}\)</span>, the outcome variable <span class="math inline">\(y\)</span>, and the error term <span class="math inline">\(\epsilon\)</span>. It depends on how we define the “population” to decide how Bootstrap could be used<label for="tufte-sn-87" class="margin-toggle sidenote-number">87</label><input type="checkbox" id="tufte-sn-87" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">87</span> Remember that, Bootstrap is a computational procedure to mimic the sampling process from a <em>population</em>. So, when you deal with a problem, you need to determine first what is the population.</span>.</p>
<p>A variety of options could be obtained. Below are some examples.</p>
<p><!-- begin{enumerate} --></p>
<p>1. [Option 1.] We could simply resample the data points (i.e., the (<span class="math inline">\(\boldsymbol{x}_n\)</span>,<span class="math inline">\(y_n\)</span>) pairs) following the nonparametric Bootstrap scheme shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a>. For each sampled dataset, we fit a regression model and obtain the fitted regression parameters.</p>
<p>2. [Option 2.] We could fix the <span class="math inline">\(\boldsymbol{x}\)</span>, and only sample for <span class="math inline">\(y\)</span>.<label for="tufte-sn-88" class="margin-toggle sidenote-number">88</label><input type="checkbox" id="tufte-sn-88" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">88</span> In this way we implicitly assume that the uncertainty of the dataset mainly comes from <span class="math inline">\(y\)</span>.</span> To sample <span class="math inline">\(y\)</span>, we draw samples using a fitted conditional distribution model <span class="math inline">\(P(y|\boldsymbol{x})\)</span>.<label for="tufte-sn-89" class="margin-toggle sidenote-number">89</label><input type="checkbox" id="tufte-sn-89" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">89</span> We could use kernel density estimation approaches, which are not introduced in this book. Interested readers could explore the R package <code>kdensity</code> and read the monograph by Silverman, B.W., <em>Density Estimation for Statistics and Data Analysis</em>, Chapman &amp; Hall/CRC, 1986. A related method, called <em>Kernel regression</em> model, can be found in <strong>Chapter 9</strong>.</span> Then, for each sampled dataset, we fit a regression model and obtain the fitted parameters.</p>
<p>3. [Option 3.] We could simulate new samples of <span class="math inline">\(\boldsymbol{x}\)</span> using the nonparametric Bootstrap method on the samples of <span class="math inline">\(\boldsymbol{x}\)</span> only. Then, for the new samples of <span class="math inline">\(\boldsymbol{x}\)</span>, we draw samples of <span class="math inline">\(y\)</span> using the fitted conditional distribution model <span class="math inline">\(P(y|\boldsymbol{x})\)</span>. This is a combination of the nonparametric and parametric Bootstrap methods. Then, for each sampled dataset, we can fit a regression model and obtain the fitted regression parameters.</p>
<p><!-- end{enumerate} --></p>
<p>Via either option, we could obtain an empirical distribution of the estimated regression parameter and compute a curve like the one shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a>. For instance, suppose we repeat this process <span class="math inline">\(10,000\)</span> times. We can obtain <span class="math inline">\(10,000\)</span> sets of estimated regression parameters, then we can use these samples to evaluate the sampling distribution of the regression parameters. We can also see if the parameters are significantly different from <span class="math inline">\(0\)</span>, and derive their <span class="math inline">\(95\%\)</span> confidence intervals.</p>
<p>The three options above are just some examples<label for="tufte-sn-90" class="margin-toggle sidenote-number">90</label><input type="checkbox" id="tufte-sn-90" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">90</span> Options 1 and 3 both define the population as the joint distribution of <span class="math inline">\(\boldsymbol{x}\)</span> and <span class="math inline">\(y\)</span>, but differ in the ways to draw samples. Option 2 defines the population as <span class="math inline">\(P(y|\boldsymbol{x})\)</span> only.</span>. As a more complicated model than simple parametric estimation in distribution fitting, how to conduct Bootstrap on regression models (and other complex models such as time series models or decision tree models) is a challenging problem.</p>
</div>
<div id="r-lab-4" class="section level3 unnumbered">
<h3>R Lab</h3>
<p><em>4-Step R Pipeline.</em> <strong>Step 1</strong> is to load the dataset into the R workspace.</p>
<p></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1 -&gt; Read data into R workstation</span></span>
<span id="cb69-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="co"># RCurl is the R package to read csv file using a link</span></span>
<span id="cb69-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RCurl)</span>
<span id="cb69-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb69-4" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;https://raw.githubusercontent.com&quot;</span>,</span>
<span id="cb69-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb69-5" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;/analyticsbook/book/main/data/AD.csv&quot;</span>)</span>
<span id="cb69-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb69-6" aria-hidden="true" tabindex="-1"></a>AD <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">text=</span><span class="fu">getURL</span>(url))</span></code></pre></div>
<p></p>
<p><strong>Step 2</strong> is to implement Bootstrap on a model. Here, let’s implement Bootstrap on the parameter estimation problem for normal distribution fitting. We obtain results using both the analytic approach and the Bootstrapped approach, so we could evaluate how well the Bootstrap works.</p>
<p>Specifically, let’s pick up the variable <code>HippoNV</code>, and estimate its mean for the normal subjects<label for="tufte-sn-91" class="margin-toggle sidenote-number">91</label><input type="checkbox" id="tufte-sn-91" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">91</span> Recall that we have both <em>normal</em> and <em>diseased</em> populations in our dataset.</span>. Assuming that the variable <code>HippoNV</code> is distributed as a normal distribution, we could use the <code>fitdistr()</code> function from the R package <code>MASS</code> to estimate the mean and standard derivation, as shown below.</p>
<p></p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2 -&gt; Decide on the statistical operation </span></span>
<span id="cb70-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="co"># that you want to &quot;Bootstrap&quot; with</span></span>
<span id="cb70-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(MASS)</span>
<span id="cb70-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb70-4" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">fitdistr</span>(AD<span class="sc">$</span>HippoNV, <span class="at">densfun=</span><span class="st">&quot;normal&quot;</span>)  </span>
<span id="cb70-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb70-5" aria-hidden="true" tabindex="-1"></a><span class="co"># fitdistr() is a function from the package &quot;MASS&quot;. </span></span>
<span id="cb70-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb70-6" aria-hidden="true" tabindex="-1"></a><span class="co"># It can fit a range of distributions, e.g., by using the argument, </span></span>
<span id="cb70-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb70-7" aria-hidden="true" tabindex="-1"></a><span class="co"># densfun=&quot;normal&quot;, we fit a normal distribution.</span></span></code></pre></div>
<p></p>
<p>The <code>fitdistr()</code> function returns the estimated parameters together with their standard derivation<label for="tufte-sn-92" class="margin-toggle sidenote-number">92</label><input type="checkbox" id="tufte-sn-92" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">92</span> Here, the standard derivation of the estimated parameters is derived based on the assumption of normality of <code>HippoNV</code>. This is a theoretical result, in contrast with the computational result by Bootstrap shown later.</span>, and the <span class="math inline">\(95\%\)</span> CI of the estimated mean.</p>
<p></p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb71-1" aria-hidden="true" tabindex="-1"></a>fit</span>
<span id="cb71-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="do">##       mean           sd     </span></span>
<span id="cb71-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="do">##   0.471662891   0.076455789 </span></span>
<span id="cb71-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="do">##  (0.003362522) (0.002377662)</span></span>
<span id="cb71-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb71-5" aria-hidden="true" tabindex="-1"></a>lower.bound <span class="ot">=</span> fit<span class="sc">$</span>estimate[<span class="dv">1</span>] <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> fit<span class="sc">$</span>sd[<span class="dv">2</span>]</span>
<span id="cb71-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb71-6" aria-hidden="true" tabindex="-1"></a>upper.bound <span class="ot">=</span> fit<span class="sc">$</span>estimate[<span class="dv">1</span>] <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> fit<span class="sc">$</span>sd[<span class="dv">2</span>]</span>
<span id="cb71-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb71-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound   upper.bound     </span></span>
<span id="cb71-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb71-8" aria-hidden="true" tabindex="-1"></a><span class="do">##    0.4670027     0.4763231 </span></span></code></pre></div>
<p></p>
<p><strong>Step 3</strong> implements the nonparametric Bootstrap scheme<label for="tufte-sn-93" class="margin-toggle sidenote-number">93</label><input type="checkbox" id="tufte-sn-93" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">93</span> The one shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-2">59</a>.</span>, as an alternative approach, to obtain the <span class="math inline">\(95\%\)</span> CI of the estimated mean.</p>
<p></p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3 -&gt; draw R bootstrap replicates to </span></span>
<span id="cb72-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-2" aria-hidden="true" tabindex="-1"></a><span class="co"># conduct the selected statistical operation</span></span>
<span id="cb72-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-3" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb72-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the vector to store the bootstrapped estimates</span></span>
<span id="cb72-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-5" aria-hidden="true" tabindex="-1"></a>bs_mean <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, R)</span>
<span id="cb72-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-6" aria-hidden="true" tabindex="-1"></a><span class="co"># draw R bootstrap resamples and obtain the estimates</span></span>
<span id="cb72-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>R) {</span>
<span id="cb72-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-8" aria-hidden="true" tabindex="-1"></a>  resam1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(AD<span class="sc">$</span>HippoNV, <span class="fu">length</span>(AD<span class="sc">$</span>HippoNV), </span>
<span id="cb72-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-9" aria-hidden="true" tabindex="-1"></a>                   <span class="at">replace =</span> <span class="cn">TRUE</span>) </span>
<span id="cb72-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># resam1 is a bootstrapped dataset. </span></span>
<span id="cb72-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-11" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">fitdistr</span>(resam1 , <span class="at">densfun=</span><span class="st">&quot;normal&quot;</span>)  </span>
<span id="cb72-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># store the bootstrapped estimates of the mean</span></span>
<span id="cb72-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-13" aria-hidden="true" tabindex="-1"></a>  bs_mean[i] <span class="ot">&lt;-</span> fit<span class="sc">$</span>estimate[<span class="dv">1</span>] </span>
<span id="cb72-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb72-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p></p>
<p>Here, <span class="math inline">\(10,000\)</span> replications are simulated by the Bootstrap method. The <code>bs_mean</code> is a vector of <span class="math inline">\(10,000\)</span> elements to record all the estimated mean parameter in these replications. These <span class="math inline">\(10,000\)</span> estimated parameters could be taken as a set of samples.</p>
<p><strong>Step 4</strong> is to summarize the Bootstrapped samples, i.e., to compute the <span class="math inline">\(95\%\)</span> CI of the estimated mean, as shown below.</p>
<p></p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4 -&gt; Summarize the results and derive the</span></span>
<span id="cb73-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="co"># bootstrap confidence interval (CI) of the parameter</span></span>
<span id="cb73-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co"># sort the mean estimates to obtain quantiles needed</span></span>
<span id="cb73-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co"># to construct the CIs</span></span>
<span id="cb73-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-5" aria-hidden="true" tabindex="-1"></a>bs_mean.sorted <span class="ot">&lt;-</span> <span class="fu">sort</span>(bs_mean) </span>
<span id="cb73-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.025th and 0.975th quantile gives equal-tail bootstrap CI</span></span>
<span id="cb73-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-7" aria-hidden="true" tabindex="-1"></a>CI.bs <span class="ot">&lt;-</span> <span class="fu">c</span>(bs_mean.sorted[<span class="fu">round</span>(<span class="fl">0.025</span><span class="sc">*</span>R)],</span>
<span id="cb73-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-8" aria-hidden="true" tabindex="-1"></a>                        bs_mean.sorted[<span class="fu">round</span>(<span class="fl">0.975</span><span class="sc">*</span>R<span class="sc">+</span><span class="dv">1</span>)])</span>
<span id="cb73-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-9" aria-hidden="true" tabindex="-1"></a>CI.bs</span>
<span id="cb73-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-10" aria-hidden="true" tabindex="-1"></a><span class="do">##   lower.bound   upper.bound     </span></span>
<span id="cb73-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb73-11" aria-hidden="true" tabindex="-1"></a><span class="do">##    0.4656406     0.4778276 </span></span></code></pre></div>
<p></p>
<p>It is seen that the <span class="math inline">\(95\%\)</span> CI by Bootstrap is close to the <span class="math inline">\(95\%\)</span> CI in the theoretical result. This shows the validity and efficacy of the Bootstrap method to evaluate the uncertainty of a statistical operation<label for="tufte-sn-94" class="margin-toggle sidenote-number">94</label><input type="checkbox" id="tufte-sn-94" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">94</span> Bootstrap is as good as the theoretical method, but it doesn’t require to know the variable’s distribution. The cost it pays for this robustness is its computational overhead. In this example, the computation is light. For some other cases, the computation could be burdensome, i.e., when the dataset becomes big, or the statistical model itself has been computationally demanding.</span>.</p>
<p><em>Beyond the 4-step Pipeline.</em> While the estimation of the mean of <code>HippoNV</code> is a relatively simple operation, in what follows, we consider a more complex statistical operation, the comparison of the mean parameters of <code>HippoNV</code> across the two classes, <em>normal</em> and <em>diseased</em>.</p>
<p>To do so, the following R code creates a temporary dataset for this purpose.</p>
<p></p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb74-1" aria-hidden="true" tabindex="-1"></a>tempData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(AD<span class="sc">$</span>HippoNV,AD<span class="sc">$</span>DX_bl)</span>
<span id="cb74-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(tempData) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;HippoNV&quot;</span>,<span class="st">&quot;DX_bl&quot;</span>)</span>
<span id="cb74-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb74-3" aria-hidden="true" tabindex="-1"></a>tempData<span class="sc">$</span>DX_bl[<span class="fu">which</span>(tempData<span class="sc">$</span>DX_bl<span class="sc">==</span><span class="dv">0</span>)] <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Normal&quot;</span>)</span>
<span id="cb74-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb74-4" aria-hidden="true" tabindex="-1"></a>tempData<span class="sc">$</span>DX_bl[<span class="fu">which</span>(tempData<span class="sc">$</span>DX_bl<span class="sc">==</span><span class="dv">1</span>)] <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Diseased&quot;</span>)</span></code></pre></div>
<p></p>
<p>We then use <code>ggplot()</code> to visualize the two distributions by comparing their histograms.</p>
<p></p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb75-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(tempData,<span class="fu">aes</span>(<span class="at">x =</span> HippoNV, <span class="at">colour=</span>DX_bl))</span>
<span id="cb75-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb75-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..count.., <span class="at">fill=</span>DX_bl),</span>
<span id="cb75-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb75-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">alpha=</span><span class="fl">0.5</span>,<span class="at">position=</span><span class="st">&quot;identity&quot;</span>) </span>
<span id="cb75-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(p)</span></code></pre></div>
<p></p>
<p>The result is shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-6">61</a>. It could be seen that the two distributions differ from each other. To have a formal evaluation of this impression, the following R code shows how the nonparametric Bootstrap method can be implemented here.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-6"></span>
<img src="graphics/4_6.png" alt=" Histograms of `HippoNV` in the *normal* and *diseased* groups" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 61:  Histograms of <code>HippoNV</code> in the <em>normal</em> and <em>diseased</em> groups<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p></p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># draw R bootstrap replicates</span></span>
<span id="cb76-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-2" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb76-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-3" aria-hidden="true" tabindex="-1"></a><span class="co"># init location for bootstrap samples</span></span>
<span id="cb76-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-4" aria-hidden="true" tabindex="-1"></a>bs0_mean <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, R)</span>
<span id="cb76-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-5" aria-hidden="true" tabindex="-1"></a>bs1_mean <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, R)</span>
<span id="cb76-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-6" aria-hidden="true" tabindex="-1"></a><span class="co"># draw R bootstrap resamples and obtain the estimates</span></span>
<span id="cb76-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>R) {</span>
<span id="cb76-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-8" aria-hidden="true" tabindex="-1"></a>resam0 <span class="ot">&lt;-</span> <span class="fu">sample</span>(tempData<span class="sc">$</span>HippoNV[<span class="fu">which</span>(tempData<span class="sc">$</span>DX_bl<span class="sc">==</span>    <span class="st">&quot;Normal&quot;</span>)],<span class="fu">length</span>(tempData<span class="sc">$</span>HippoNV[<span class="fu">which</span>(tempData<span class="sc">$</span>DX_bl<span class="sc">==</span>                               <span class="st">&quot;Normal&quot;</span>)]),<span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb76-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-9" aria-hidden="true" tabindex="-1"></a>fit0 <span class="ot">&lt;-</span> <span class="fu">fitdistr</span>(resam0 , <span class="at">densfun=</span><span class="st">&quot;normal&quot;</span>)  </span>
<span id="cb76-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-10" aria-hidden="true" tabindex="-1"></a>bs0_mean[i] <span class="ot">&lt;-</span> fit0<span class="sc">$</span>estimate[<span class="dv">1</span>]</span>
<span id="cb76-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-11" aria-hidden="true" tabindex="-1"></a>resam1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(tempData<span class="sc">$</span>HippoNV[<span class="fu">which</span>(tempData<span class="sc">$</span>DX_bl<span class="sc">==</span>               <span class="st">&quot;Diseased&quot;</span>)],</span>
<span id="cb76-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-12" aria-hidden="true" tabindex="-1"></a>         <span class="fu">length</span>(tempData<span class="sc">$</span>HippoNV[<span class="fu">which</span>(tempData<span class="sc">$</span>DX_bl<span class="sc">==</span>               <span class="st">&quot;Diseased&quot;</span>)]),<span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb76-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-13" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">fitdistr</span>(resam1 , <span class="at">densfun=</span><span class="st">&quot;normal&quot;</span>) </span>
<span id="cb76-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-14" aria-hidden="true" tabindex="-1"></a>bs1_mean[i] <span class="ot">&lt;-</span> fit1<span class="sc">$</span>estimate[<span class="dv">1</span>]</span>
<span id="cb76-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb76-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-17" aria-hidden="true" tabindex="-1"></a>bs_meanDiff <span class="ot">&lt;-</span> bs0_mean <span class="sc">-</span> bs1_mean</span>
<span id="cb76-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-19"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-19" aria-hidden="true" tabindex="-1"></a><span class="co"># sort the mean estimates to obtain bootstrap CI</span></span>
<span id="cb76-20"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-20" aria-hidden="true" tabindex="-1"></a>bs_meanDiff.sorted <span class="ot">&lt;-</span> <span class="fu">sort</span>(bs_meanDiff)</span>
<span id="cb76-21"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.025th and 0.975th quantile gives equal-tail bootstrap CI</span></span>
<span id="cb76-22"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-22" aria-hidden="true" tabindex="-1"></a>CI.bs <span class="ot">&lt;-</span> <span class="fu">c</span>(bs_meanDiff.sorted[<span class="fu">round</span>(<span class="fl">0.025</span><span class="sc">*</span>R)],</span>
<span id="cb76-23"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-23" aria-hidden="true" tabindex="-1"></a>           bs_meanDiff.sorted[<span class="fu">round</span>(<span class="fl">0.975</span><span class="sc">*</span>R<span class="sc">+</span><span class="dv">1</span>)])</span>
<span id="cb76-24"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb76-24" aria-hidden="true" tabindex="-1"></a>CI.bs</span></code></pre></div>
<p></p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-7"></span>
<img src="graphics/4_7.png" alt="Histogram of the estimated mean difference of `HippoNV` in the two groups by Bootstrap with $10,000$ replications " width="100%"  />
<!--
<p class="caption marginnote">-->Figure 62: Histogram of the estimated mean difference of <code>HippoNV</code> in the two groups by Bootstrap with <span class="math inline">\(10,000\)</span> replications <!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>The <span class="math inline">\(95\%\)</span> CI of the difference of the two mean parameters is</p>
<p></p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb77-1" aria-hidden="true" tabindex="-1"></a>CI.bs</span>
<span id="cb77-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.08066058 0.10230428</span></span></code></pre></div>
<p></p>
<p>The following R code draws a histogram of the <code>bs_meanDiff</code> to give us visual information about the Bootstrapped estimation of the mean difference, which is shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-7">62</a>. The difference is statistically significant.</p>
<p></p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the bootstrap distribution with CI</span></span>
<span id="cb78-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="co"># First put data in data.frame for ggplot()</span></span>
<span id="cb78-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-3" aria-hidden="true" tabindex="-1"></a>dat.bs_meanDiff <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(bs_meanDiff)</span>
<span id="cb78-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb78-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-6" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dat.bs_meanDiff, <span class="fu">aes</span>(<span class="at">x =</span> bs_meanDiff))</span>
<span id="cb78-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-7" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y=</span>..density..))</span>
<span id="cb78-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-8" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">alpha=</span><span class="fl">0.1</span>, <span class="at">fill=</span><span class="st">&quot;white&quot;</span>)</span>
<span id="cb78-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-9" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_rug</span>()</span>
<span id="cb78-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-10" aria-hidden="true" tabindex="-1"></a><span class="co"># vertical line at CI</span></span>
<span id="cb78-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-11" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span>CI.bs[<span class="dv">1</span>], <span class="at">colour=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb78-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-12" aria-hidden="true" tabindex="-1"></a>                    <span class="at">linetype=</span><span class="st">&quot;longdash&quot;</span>)</span>
<span id="cb78-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-13" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span>CI.bs[<span class="dv">2</span>], <span class="at">colour=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb78-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-14" aria-hidden="true" tabindex="-1"></a>                    <span class="at">linetype=</span><span class="st">&quot;longdash&quot;</span>)</span>
<span id="cb78-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-15" aria-hidden="true" tabindex="-1"></a>title <span class="ot">=</span> <span class="st">&quot;Bootstrap distribution of the estimated mean</span></span>
<span id="cb78-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-16" aria-hidden="true" tabindex="-1"></a><span class="st">         difference of HippoNV between normal and diseased&quot;</span></span>
<span id="cb78-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-17" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span>title)</span>
<span id="cb78-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb78-18" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(p)</span></code></pre></div>
<p></p>
<p>We can also apply Bootstrap on linear regression. In <strong>Chapter 2</strong> we have fitted a regression model of <code>MMSCORE</code> and presented the analytically derived standard derivation of the estimated regression parameters<label for="tufte-sn-95" class="margin-toggle sidenote-number">95</label><input type="checkbox" id="tufte-sn-95" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">95</span> I.e., as shown in Eq. <a href="chapter-2.-abstraction-regression-tree-models.html#eq:2-betaDist">(19)</a>.</span>. Here, we show that we could use Bootstrap to compute the <span class="math inline">\(95\%\)</span> CI of the regression parameters as well.</p>
<p>First, we fit a linear regression model.</p>
<p></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a regression model first, for comparison</span></span>
<span id="cb79-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-2" aria-hidden="true" tabindex="-1"></a>tempData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(AD<span class="sc">$</span>MMSCORE,AD<span class="sc">$</span>AGE, AD<span class="sc">$</span>PTGENDER, AD<span class="sc">$</span>PTEDUCAT)</span>
<span id="cb79-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-3" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(tempData) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;MMSCORE&quot;</span>,<span class="st">&quot;AGE&quot;</span>,<span class="st">&quot;PTGENDER&quot;</span>,<span class="st">&quot;PTEDUCAT&quot;</span>)</span>
<span id="cb79-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-4" aria-hidden="true" tabindex="-1"></a>lm.AD <span class="ot">&lt;-</span> <span class="fu">lm</span>(MMSCORE <span class="sc">~</span>  AGE <span class="sc">+</span> PTGENDER <span class="sc">+</span> PTEDUCAT, <span class="at">data =</span> tempData)</span>
<span id="cb79-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-5" aria-hidden="true" tabindex="-1"></a>sum.lm.AD <span class="ot">&lt;-</span> <span class="fu">summary</span>(lm.AD)</span>
<span id="cb79-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Age is not significant according to the p-value</span></span>
<span id="cb79-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-7" aria-hidden="true" tabindex="-1"></a>std.lm <span class="ot">&lt;-</span> sum.lm.AD<span class="sc">$</span>coefficients[ , <span class="dv">2</span>]</span>
<span id="cb79-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-8" aria-hidden="true" tabindex="-1"></a>lm.AD<span class="sc">$</span>coefficients[<span class="dv">2</span>] <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> std.lm[<span class="dv">2</span>]</span>
<span id="cb79-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb79-9" aria-hidden="true" tabindex="-1"></a>lm.AD<span class="sc">$</span>coefficients[<span class="dv">2</span>] <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> std.lm[<span class="dv">2</span>]</span></code></pre></div>
<p></p>
<p>The fitted regression model is</p>
<p></p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb80-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Call:</span></span>
<span id="cb80-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="do">## lm(formula = MMSCORE   AGE + PTGENDER + PTEDUCAT,</span></span>
<span id="cb80-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="do">##                    data = tempData)</span></span>
<span id="cb80-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-5" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb80-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Residuals:</span></span>
<span id="cb80-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-7" aria-hidden="true" tabindex="-1"></a><span class="do">##     Min      1Q  Median      3Q     Max </span></span>
<span id="cb80-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-8" aria-hidden="true" tabindex="-1"></a><span class="do">## -8.4290 -0.9766  0.5796  1.4252  3.4539 </span></span>
<span id="cb80-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-9" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb80-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Coefficients:</span></span>
<span id="cb80-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-11" aria-hidden="true" tabindex="-1"></a><span class="do">##             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb80-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-12" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept) 27.70377    1.11131  24.929  &lt; 2e-16 ***</span></span>
<span id="cb80-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-13" aria-hidden="true" tabindex="-1"></a><span class="do">## AGE         -0.02453    0.01282  -1.913   0.0563 .  </span></span>
<span id="cb80-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-14" aria-hidden="true" tabindex="-1"></a><span class="do">## PTGENDER    -0.43356    0.18740  -2.314   0.0211 *  </span></span>
<span id="cb80-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-15" aria-hidden="true" tabindex="-1"></a><span class="do">## PTEDUCAT     0.17120    0.03432   4.988 8.35e-07 ***</span></span>
<span id="cb80-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-16" aria-hidden="true" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb80-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 </span></span>
<span id="cb80-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-18" aria-hidden="true" tabindex="-1"></a><span class="do">## &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb80-19"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-19" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb80-20"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Residual standard error: 2.062 on 513 degrees of freedom</span></span>
<span id="cb80-21"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-21" aria-hidden="true" tabindex="-1"></a><span class="do">## Multiple R-squared:  0.0612, Adjusted R-squared:  0.05571 </span></span>
<span id="cb80-22"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-22" aria-hidden="true" tabindex="-1"></a><span class="do">## F-statistic: 11.15 on 3 and 513 DF,  p-value: 4.245e-07</span></span>
<span id="cb80-23"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-23" aria-hidden="true" tabindex="-1"></a><span class="do">##     Lower bound   Upper bound</span></span>
<span id="cb80-24"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb80-24" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] -0.04966834   0.000600785</span></span></code></pre></div>
<p></p>
<p>Then, we follow Option 1 to conduct Bootstrap for the linear regression model.</p>
<p></p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># draw R bootstrap replicates</span></span>
<span id="cb81-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-2" aria-hidden="true" tabindex="-1"></a>R <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb81-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co"># init location for bootstrap samples</span></span>
<span id="cb81-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-4" aria-hidden="true" tabindex="-1"></a>bs_lm.AD_demo <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> R, <span class="at">ncol =</span> </span>
<span id="cb81-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-5" aria-hidden="true" tabindex="-1"></a>                          <span class="fu">length</span>(lm.AD_demo<span class="sc">$</span>coefficients))</span>
<span id="cb81-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-6" aria-hidden="true" tabindex="-1"></a><span class="co"># draw R bootstrap resamples and obtain the estimates</span></span>
<span id="cb81-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>R) {</span>
<span id="cb81-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-8" aria-hidden="true" tabindex="-1"></a>  resam_ID <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">dim</span>(tempData)[<span class="dv">1</span>]), <span class="fu">dim</span>(tempData)[<span class="dv">1</span>],</span>
<span id="cb81-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-9" aria-hidden="true" tabindex="-1"></a>                     <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb81-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-10" aria-hidden="true" tabindex="-1"></a>resam_Data <span class="ot">&lt;-</span> tempData[resam_ID,]</span>
<span id="cb81-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-11" aria-hidden="true" tabindex="-1"></a>  bs.lm.AD_demo <span class="ot">&lt;-</span> <span class="fu">lm</span>(MMSCORE <span class="sc">~</span>  AGE <span class="sc">+</span> PTGENDER <span class="sc">+</span> PTEDUCAT,</span>
<span id="cb81-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-12" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> resam_Data)</span>
<span id="cb81-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-13" aria-hidden="true" tabindex="-1"></a>bs_lm.AD_demo[i,] <span class="ot">&lt;-</span> bs.lm.AD_demo<span class="sc">$</span>coefficients</span>
<span id="cb81-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb81-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p></p>
<p>The <code>bs_lm.AD_demo</code> records the estimated regression parameters in the <span class="math inline">\(10,000\)</span> replications. The following R code shows the <span class="math inline">\(95\%\)</span> CI of <code>AGE</code> by Bootstrap.</p>
<p></p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-1" aria-hidden="true" tabindex="-1"></a>bs.AGE <span class="ot">&lt;-</span> bs_lm.AD_demo[,<span class="dv">2</span>]</span>
<span id="cb82-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="co"># sort the mean estimates of AGE to obtain bootstrap CI</span></span>
<span id="cb82-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-3" aria-hidden="true" tabindex="-1"></a>bs.AGE.sorted <span class="ot">&lt;-</span> <span class="fu">sort</span>(bs.AGE)</span>
<span id="cb82-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.025th and 0.975th quantile gives equal-tail</span></span>
<span id="cb82-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-6" aria-hidden="true" tabindex="-1"></a><span class="co"># bootstrap CI</span></span>
<span id="cb82-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-7" aria-hidden="true" tabindex="-1"></a>CI.bs <span class="ot">&lt;-</span> <span class="fu">c</span>(bs.AGE.sorted[<span class="fu">round</span>(<span class="fl">0.025</span><span class="sc">*</span>R)],</span>
<span id="cb82-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-8" aria-hidden="true" tabindex="-1"></a>       bs.AGE.sorted[<span class="fu">round</span>(<span class="fl">0.975</span><span class="sc">*</span>R<span class="sc">+</span><span class="dv">1</span>)])</span>
<span id="cb82-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb82-9" aria-hidden="true" tabindex="-1"></a>CI.bs</span></code></pre></div>
<p></p>
<p>It is clear that the 95<span class="math inline">\(\%\)</span> CI of <code>AGE</code> includes <span class="math inline">\(0\)</span> in the range. This is consistent with the result by t-test that shows the variable <code>AGE</code> is insignificant (i.e., p-value<span class="math inline">\(=0.0563\)</span>). We can also see that the <span class="math inline">\(95\%\)</span> CI by Bootstrap is close to the <span class="math inline">\(95\%\)</span> CI by theoretical result.</p>
<p></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb83-1" aria-hidden="true" tabindex="-1"></a>CI.bs</span>
<span id="cb83-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="do">##     Lower bound   Upper bound</span></span>
<span id="cb83-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] -0.053940482  0.005090523</span></span></code></pre></div>
<p></p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-8"></span>
<img src="graphics/4_8.png" alt="Histogram of the estimated regression parameter of `AGE` by Bootstrap with $10,000$ replications" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 63: Histogram of the estimated regression parameter of <code>AGE</code> by Bootstrap with <span class="math inline">\(10,000\)</span> replications<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>The following R codes draw a histogram of the Bootstrapped estimation of the regression parameter of <code>AGE</code> to give us a visual examination about the Bootstrapped estimation, which is shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-8">63</a>.</p>
<p></p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the bootstrap distribution with CI</span></span>
<span id="cb84-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-2" aria-hidden="true" tabindex="-1"></a><span class="co"># First put data in data.frame for ggplot()</span></span>
<span id="cb84-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-3" aria-hidden="true" tabindex="-1"></a>dat.bs.AGE <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(bs.AGE.sorted)</span>
<span id="cb84-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb84-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-6" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dat.bs.AGE, <span class="fu">aes</span>(<span class="at">x =</span> bs.AGE))</span>
<span id="cb84-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-7" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y=</span>..density..))</span>
<span id="cb84-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-8" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">alpha=</span><span class="fl">0.1</span>, <span class="at">fill=</span><span class="st">&quot;white&quot;</span>)</span>
<span id="cb84-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-9" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_rug</span>()</span>
<span id="cb84-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-10" aria-hidden="true" tabindex="-1"></a><span class="co"># vertical line at CI</span></span>
<span id="cb84-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-11" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span>CI.bs[<span class="dv">1</span>], <span class="at">colour=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb84-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-12" aria-hidden="true" tabindex="-1"></a>                    <span class="at">linetype=</span><span class="st">&quot;longdash&quot;</span>)</span>
<span id="cb84-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-13" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span>CI.bs[<span class="dv">2</span>], <span class="at">colour=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb84-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-14" aria-hidden="true" tabindex="-1"></a>                    <span class="at">linetype=</span><span class="st">&quot;longdash&quot;</span>)</span>
<span id="cb84-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-15" aria-hidden="true" tabindex="-1"></a>title <span class="ot">&lt;-</span> <span class="st">&quot;Bootstrap distribution of the estimated </span></span>
<span id="cb84-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-16" aria-hidden="true" tabindex="-1"></a><span class="st">                          regression parameter of AGE&quot;</span></span>
<span id="cb84-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-17" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> title)</span>
<span id="cb84-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb84-18" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(p)</span></code></pre></div>
<p></p>
<p>We can also see the <span class="math inline">\(95\%\)</span> CI of <code>PTEDUCAT</code> as shown below, which is between <span class="math inline">\(0.1021189\)</span> and <span class="math inline">\(0.2429209\)</span>. This is also close to the the <span class="math inline">\(95\%\)</span> CI by theoretical result. Also, t-test also shows the variable <code>PTEDUCAT</code> is significant (i.e., p-value is <span class="math inline">\(8.35e-07\)</span>).</p>
<p></p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-1" aria-hidden="true" tabindex="-1"></a>bs.PTEDUCAT <span class="ot">&lt;-</span> bs_lm.AD_demo[,<span class="dv">4</span>]</span>
<span id="cb85-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="co"># sort the mean estimates of PTEDUCAT to obtain</span></span>
<span id="cb85-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="co"># bootstrap CI</span></span>
<span id="cb85-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-4" aria-hidden="true" tabindex="-1"></a>bs.PTEDUCAT.sorted <span class="ot">&lt;-</span> <span class="fu">sort</span>(bs.PTEDUCAT)</span>
<span id="cb85-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 0.025th and 0.975th quantile gives equal-tail</span></span>
<span id="cb85-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-7" aria-hidden="true" tabindex="-1"></a><span class="co"># bootstrap CI</span></span>
<span id="cb85-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-8" aria-hidden="true" tabindex="-1"></a>CI.bs <span class="ot">&lt;-</span> <span class="fu">c</span>(bs.PTEDUCAT.sorted[<span class="fu">round</span>(<span class="fl">0.025</span><span class="sc">*</span>R)],</span>
<span id="cb85-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-9" aria-hidden="true" tabindex="-1"></a>           bs.PTEDUCAT.sorted[<span class="fu">round</span>(<span class="fl">0.975</span><span class="sc">*</span>R<span class="sc">+</span><span class="dv">1</span>)])</span>
<span id="cb85-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-10" aria-hidden="true" tabindex="-1"></a>CI.bs</span>
<span id="cb85-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-11" aria-hidden="true" tabindex="-1"></a>CI.bs</span>
<span id="cb85-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb85-12" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.1021189 0.2429209</span></span></code></pre></div>
<p></p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-9"></span>
<img src="graphics/4_9.png" alt="Histogram of the estimated regression parameter of `PTEDUCAT` by Bootstrap with $10,000$ replications " width="100%"  />
<!--
<p class="caption marginnote">-->Figure 64: Histogram of the estimated regression parameter of <code>PTEDUCAT</code> by Bootstrap with <span class="math inline">\(10,000\)</span> replications <!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>The following R code draws a histogram (i.e., Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-9">64</a>) of the Bootstrapped estimation of the regression parameter of <code>PTEDUCAT</code>.</p>
<p></p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Plot the bootstrap distribution with CI</span></span>
<span id="cb86-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-2" aria-hidden="true" tabindex="-1"></a><span class="co"># First put data in data.frame for ggplot()</span></span>
<span id="cb86-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-3" aria-hidden="true" tabindex="-1"></a>dat.bs.PTEDUCAT <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(bs.PTEDUCAT.sorted)</span>
<span id="cb86-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb86-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-6" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dat.bs.PTEDUCAT, <span class="fu">aes</span>(<span class="at">x =</span> bs.PTEDUCAT))</span>
<span id="cb86-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-7" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y=</span>..density..))</span>
<span id="cb86-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-8" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_density</span>(<span class="at">alpha=</span><span class="fl">0.1</span>, <span class="at">fill=</span><span class="st">&quot;white&quot;</span>)</span>
<span id="cb86-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-9" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_rug</span>()</span>
<span id="cb86-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-10" aria-hidden="true" tabindex="-1"></a><span class="co"># vertical line at CI</span></span>
<span id="cb86-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-11" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span>CI.bs[<span class="dv">1</span>], <span class="at">colour=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb86-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-12" aria-hidden="true" tabindex="-1"></a>                    <span class="at">linetype=</span><span class="st">&quot;longdash&quot;</span>)</span>
<span id="cb86-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-13" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">geom_vline</span>(<span class="at">xintercept=</span>CI.bs[<span class="dv">2</span>], <span class="at">colour=</span><span class="st">&quot;blue&quot;</span>,</span>
<span id="cb86-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-14" aria-hidden="true" tabindex="-1"></a>                    <span class="at">linetype=</span><span class="st">&quot;longdash&quot;</span>)</span>
<span id="cb86-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-15" aria-hidden="true" tabindex="-1"></a>title <span class="ot">&lt;-</span> <span class="st">&quot;Bootstrap distribution of the estimated regression</span></span>
<span id="cb86-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-16" aria-hidden="true" tabindex="-1"></a><span class="st">                                      parameter of PTEDUCAT&quot;</span></span>
<span id="cb86-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-17" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> title )</span>
<span id="cb86-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb86-18" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(p)</span></code></pre></div>
<p></p>
</div>
</div>
<div id="random-forests" class="section level2 unnumbered">
<h2>Random forests</h2>
<div id="rationale-and-formulation-6" class="section level3 unnumbered">
<h3>Rationale and formulation</h3>
<p>Randomness has a productive dimension, depending on how you use it. For example, a <strong>random forest</strong> (<strong>RF</strong>) model consists of multiple tree models that are generated by a creative use of two types of randomness. One, each tree is built on a <em>randomly selected</em> set of samples by applying Bootstrap on the original dataset. Two, in building each tree, a <em>randomly selected</em> subset of features is used to choose the best split. Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-10">65</a> shows this scheme of random forest.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-10"></span>
<img src="graphics/4_10.png" alt="How random forest uses Bootstrap to grow decision trees" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 65: How random forest uses Bootstrap to grow decision trees<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>Random forest has gained superior performances in many applications, and it (together with its variants) has been a winning approach in some data competitions over the past years. While it is not necessary that an aggregation of many models would lead to better performance than its constituting parts, random forest works because of a number of reasons. Here we use an example to show when the random forest, as a sum, is better than its parts (i.e., the decision trees).</p>
<p>The following R code generates a dataset with two predictors and an outcome variable that has two classes. As shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-11">66</a> (left), the two classes are separable by a linear boundary.</p>
<p></p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a script for simulation study</span></span>
<span id="cb87-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(<span class="at">list =</span> <span class="fu">ls</span>(<span class="at">all =</span> <span class="cn">TRUE</span>))</span>
<span id="cb87-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(rpart)</span>
<span id="cb87-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-4" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(dplyr)</span>
<span id="cb87-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(ggplot2)</span>
<span id="cb87-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-6" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(randomForest)</span>
<span id="cb87-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-7" aria-hidden="true" tabindex="-1"></a>ndata <span class="ot">&lt;-</span> <span class="dv">2000</span></span>
<span id="cb87-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-8" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">runif</span>(ndata, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>)</span>
<span id="cb87-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-9" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">runif</span>(ndata, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>)</span>
<span id="cb87-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-10" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(X1, X2)</span>
<span id="cb87-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-11" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">X12 =</span> <span class="fl">0.5</span> <span class="sc">*</span> (X1 <span class="sc">-</span> X2),</span>
<span id="cb87-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-12" aria-hidden="true" tabindex="-1"></a>                        <span class="at">Y =</span> <span class="fu">ifelse</span>(X12 <span class="sc">&gt;=</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb87-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-13" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>X12) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">Y =</span></span>
<span id="cb87-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-14" aria-hidden="true" tabindex="-1"></a>                           <span class="fu">as.factor</span>(<span class="fu">as.character</span>(Y)))</span>
<span id="cb87-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-15" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> X1, <span class="at">y =</span> X2, <span class="at">color =</span> Y)) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb87-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb87-16" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Data points&quot;</span>)</span></code></pre></div>
<p></p>
<p></p>
<div class="figure"><span style="display:block;" id="fig:f4-11"></span>
<p class="caption marginnote shownote">
Figure 66: (Left) A linearly separable dataset with two predictors; (middle) the decision boundary of a decision tree model; (right) the decision boundary of a random forest model
</p>
<img src="graphics/4_11.png" alt="(Left) A linearly separable dataset with two predictors; (middle) the decision boundary of a decision tree model; (right) the decision boundary of a random forest model" width="30%"  /><img src="graphics/4_12.png" alt="(Left) A linearly separable dataset with two predictors; (middle) the decision boundary of a decision tree model; (right) the decision boundary of a random forest model" width="30%"  /><img src="graphics/4_13.png" alt="(Left) A linearly separable dataset with two predictors; (middle) the decision boundary of a decision tree model; (right) the decision boundary of a random forest model" width="30%"  />
</div>
<p></p>
<p>Both random forest and decision tree models are applied to the dataset. The classification boundaries of both decision tree and random forest models are shown in Figures <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-11">66</a> (middle) and (right), respectively.</p>
<p></p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-1" aria-hidden="true" tabindex="-1"></a>rf_model <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(Y <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb88-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-2" aria-hidden="true" tabindex="-1"></a>tree_model <span class="ot">&lt;-</span> <span class="fu">rpart</span>(Y <span class="sc">~</span> ., <span class="at">data =</span> data)</span>
<span id="cb88-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-4" aria-hidden="true" tabindex="-1"></a>pred_rf <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_model, data, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[, <span class="dv">1</span>]</span>
<span id="cb88-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-5" aria-hidden="true" tabindex="-1"></a>pred_tree <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree_model, data, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[, <span class="dv">1</span>]</span>
<span id="cb88-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-6" aria-hidden="true" tabindex="-1"></a>data_pred <span class="ot">&lt;-</span> data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">pred_rf_class =</span> <span class="fu">ifelse</span>(pred_rf <span class="sc">&lt;</span></span>
<span id="cb88-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-7" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">pred_rf_class =</span></span>
<span id="cb88-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.factor</span>(<span class="fu">as.character</span>(pred_rf_class))) <span class="sc">%&gt;%</span></span>
<span id="cb88-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">pred_tree_class =</span> <span class="fu">ifelse</span>(pred_tree <span class="sc">&lt;</span> </span>
<span id="cb88-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-10" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">pred_tree_class =</span></span>
<span id="cb88-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-11" aria-hidden="true" tabindex="-1"></a>                     <span class="fu">as.factor</span>(<span class="fu">as.character</span>(pred_tree_class)))</span>
<span id="cb88-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data_pred, <span class="fu">aes</span>(<span class="at">x =</span> X1, <span class="at">y =</span> X2, </span>
<span id="cb88-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-13" aria-hidden="true" tabindex="-1"></a>                      <span class="at">color =</span> pred_tree_class)) <span class="sc">+</span></span>
<span id="cb88-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Classification boundary from</span></span>
<span id="cb88-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-15" aria-hidden="true" tabindex="-1"></a><span class="st">                      a single decision tree&quot;</span>) </span>
<span id="cb88-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data_pred, <span class="fu">aes</span>(<span class="at">x =</span> X1, <span class="at">y =</span> X2, </span>
<span id="cb88-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-17" aria-hidden="true" tabindex="-1"></a>                      <span class="at">color =</span> pred_rf_class)) <span class="sc">+</span></span>
<span id="cb88-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Classification bounday from</span></span>
<span id="cb88-19"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb88-19" aria-hidden="true" tabindex="-1"></a><span class="st">                      random forests&quot;</span>)</span></code></pre></div>
<p></p>
<p>We can see from Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-11">66</a> (middle) that the classification boundary generated by the decision tree model has a difficult to approximate linear boundary. There is an inherent limitation of a tree model to fit smooth boundaries due to its box-shaped nature resulting from its use of rules to segment the data space for making predictions. In contrast, the classification boundary of the random forest model is smoother than the one of the decision tree, and it can provide better approximation of complex and nonlinear classification boundaries.</p>
<p>Having said that, this is not the only reason <em>why</em> the random forest model is remarkable. After all, many models can model linear boundary, and it is actually not the random forests’ strength. The remarkable thing about a random forest is its capacity, as a tree-based model, to actually model linear boundary. It shows its flexibility, adaptability, and learning capacity to characterize complex patterns in a dataset. Let’s see more details to understand how it works.</p>
</div>
<div id="theory-and-method-4" class="section level3 unnumbered">
<h3>Theory and method</h3>
<p>Like a decision tree, the learning process of random forests follows the algorithmic modeling framework. It uses an organized set of heuristics, rather than a mathematical characterization. We present the process of building random forest models using a simple example with a small dataset shown in Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t4-1">10</a> that has two predictors, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, and an outcome variable with two classes.</p>
<p></p>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:t4-1">Table 10: </span>Example of a dataset</span><!--</caption>--></p>
<table>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left"><span class="math inline">\(x_1\)</span></th>
<th align="left"><span class="math inline">\(x_2\)</span></th>
<th align="left">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C0\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(2\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(3\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(4\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(C0\)</span></td>
</tr>
</tbody>
</table>
<p></p>
<p>As shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-10">65</a>, each tree is built on a resampled dataset that consists of data instances randomly selected from the original data set<label for="tufte-sn-96" class="margin-toggle sidenote-number">96</label><input type="checkbox" id="tufte-sn-96" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">96</span> I.e., often with the same sample size as the original dataset and is called <strong>sampling with replacement</strong>.</span>. As shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-14">67</a>, the first resampled dataset includes data instances (represented by their IDs) <span class="math inline">\(\{1,1,3,4\}\)</span> and is used for building the first tree. The second resampled dataset includes data instances <span class="math inline">\(\{2,3,4,4\}\)</span> and is used for building the second tree. This process repeats until a specific number of trees is built.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-14"></span>
<img src="graphics/4_14.png" alt="Examples of bootstrapped datasets from the dataset shown in Table \@ref(tab:t4-1)" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 67: Examples of bootstrapped datasets from the dataset shown in Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t4-1">10</a><!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>The first tree begins with the root node that contains data instances <span class="math inline">\(\{1,1,3,4\}\)</span>. As introduced in <strong>Chapter 2</strong>, we recursively split a node into two child nodes to reduce impurity (i.e., measured by entropy). This greedy recursive splitting process is also used to build each decision tree in a random forest model. A slight variation is that, in the R package <code>randomForest</code>, the <strong>Gini index</strong> is used to measure impurity instead of entropy.</p>
<p>The Gini index for a data set is defined as<label for="tufte-sn-97" class="margin-toggle sidenote-number">97</label><input type="checkbox" id="tufte-sn-97" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">97</span> <span class="math inline">\(C\)</span> is the number of classes of the outcome variable, and <span class="math inline">\(p_{c}\)</span> is the proportion of data instances that come from the class <span class="math inline">\(c\)</span>.</span></p>
<p><span class="math display">\[\begin{equation*}
\small
   
\operatorname{Gini} =\sum_{c=1}^{C} p_{c}\left(1-p_{c}\right).  
 
\end{equation*}\]</span></p>
<p>The Gini index plays the same role as the entropy (more details could be found in the Remarks section). Similar as the information gain (IG), the <strong>Gini gain</strong> can be defined as</p>
<p><span class="math display">\[\begin{equation*}
\small
  \nabla \operatorname{Gini} = \operatorname{Gini}_s - \sum\nolimits_{i=1,\cdots,n} w_i \operatorname{Gini}_i. 
\end{equation*}\]</span></p>
<p>Here, <span class="math inline">\(\operatorname{Gini}_s\)</span> is the Gini index at the node to be split; <span class="math inline">\(w_{i}\)</span> and <span class="math inline">\(\operatorname{Gini}_{i}\)</span>, are the proportion of samples and the Gini index at the <span class="math inline">\(i^{th}\)</span> children node, respectively.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-16-left"></span>
<img src="graphics/4_16_v3.png" alt="root node split using $x_{1}=0$" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 68: root node split using <span class="math inline">\(x_{1}=0\)</span><!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>Let’s go back to the first tree that begins with the root node containing data instances <span class="math inline">\(\{1,1,3,4\}\)</span>. There are three instances that are associated with the class <span class="math inline">\(C0\)</span> (thus, <span class="math inline">\(p_0 = \frac{3}{4}\)</span>), one instance with <span class="math inline">\(C1\)</span> (thus, <span class="math inline">\(p_1 = \frac{1}{4}\)</span>). The Gini index of the root node is calculated as</p>
<p><span class="math display">\[\begin{equation*}
\small
   
\frac{3}{4} \times \frac{1}{4}+\frac{1}{4} \times \frac{3}{4}=0.375. 
 
\end{equation*}\]</span></p>
<p>To split the root node, candidates of splitting rules are:</p>
<p><!-- begin{enumerate} --></p>
<pre><code>\centering </code></pre>
<p>1. [Rule 1:] <span class="math inline">\(x_{1}=0 \text { versus } x_{1} \neq 0\)</span>.</p>
<p>2. [Rule 2:] <span class="math inline">\(x_{2}=0 \text { versus } x_{2} \neq 0\)</span>.</p>
<p><!-- end{enumerate} --></p>
<p>The decision tree model introduced in <strong>Chapter 2</strong> would evaluate each of the possible splitting rules, and select the one that yields the maximum Gini gain to split the node. However, for random forests, it randomly selects the variables for splitting a node<label for="tufte-sn-98" class="margin-toggle sidenote-number">98</label><input type="checkbox" id="tufte-sn-98" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">98</span> In general, for a dataset with <span class="math inline">\(p\)</span> variables, <span class="math inline">\(\sqrt{p}\)</span> variables are randomly selected for splitting.</span>. In our example, as there are two variables, we assume that <span class="math inline">\(x_{1}\)</span> is randomly selected for splitting the root node. Thus, <span class="math inline">\(x_{1}=0\)</span> is used for splitting the root node which generates the decision tree model as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-16-left">68</a>.</p>
<!-- \begin{figure*}-->
<!--    \centering-->
<!--    \checkoddpage \ifoddpage \forcerectofloat \else \forceversofloat \fi-->
<!--    \subfloat{-->
<!--        \includegraphics{graphics/4_16_v3.png}}-->
<!--    \subfloat{-->
<!--        \includegraphics{graphics/4_17_v5.png}}-->
<!--    \subfloat{-->
<!--        \includegraphics{graphics/4_18_v5.png}}-->
<!--    \caption{(Left) root node split using $x_{1}=0$; (middle) second split using $x_{2}=0$; (right) tree model trained}-->
<!--    \label{fig:4-16}-->
<!-- \end{figure*} -->
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-16-middle"></span>
<img src="graphics/4_17_v5.png" alt="second split using $x_{2}=0$" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 69: second split using <span class="math inline">\(x_{2}=0\)</span><!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>The Gini gain for the split shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-16-left">68</a> can be calculated as</p>
<p><span class="math display">\[\begin{equation*}
\small
   
0.375-0.5 \times 0-0.5 \times 0.5=0.125. 
 
\end{equation*}\]</span></p>
<p>The right node in the tree shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-16-left">68</a> has reached a perfect state of homogeneity<label for="tufte-sn-99" class="margin-toggle sidenote-number">99</label><input type="checkbox" id="tufte-sn-99" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">99</span> Which is, in practice, a rare phenomenon.</span>. The left node, however, contains two instances <span class="math inline">\(\{3,4\}\)</span> that are associated with two classes. We further split the left node. Assume that this time <span class="math inline">\(x_{2}\)</span> is randomly selected. The left node can be further split as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-16-middle">69</a>.</p>
<p>All nodes cannot be split further. The final tree model is shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-16-right">70</a>, while each leaf node is labeled with the majority class of the instances in the node, such that they become decision nodes.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-16-right"></span>
<img src="graphics/4_18_v5.png" alt="tree model trained" width="80%"  />
<!--
<p class="caption marginnote">-->Figure 70: tree model trained<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>Applying the decision tree in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-16-right">70</a> to the <span class="math inline">\(4\)</span> data points as shown in Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t4-1">10</a>, we can get the predictions as shown in Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t4-1pred">11</a>. The error rate is <span class="math inline">\(25\%\)</span>.</p>
<p></p>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:t4-1pred">Table 11: </span>Example of a dataset</span><!--</caption>--></p>
<table>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left"><span class="math inline">\(x_1\)</span></th>
<th align="left"><span class="math inline">\(x_2\)</span></th>
<th align="left">Class</th>
<th align="left">Prediction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C0\)</span></td>
<td align="left"><span class="math inline">\(C0\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(2\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
<td align="left"><span class="math inline">\(C0\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(3\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(4\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(C0\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
</tbody>
</table>
<p></p>
<p>Similarly, the second, third, …, and the <span class="math inline">\(m^{th}\)</span> trees can be built. Usually, in random forest models, tree pruning is not needed. Rather, we use a parameter to control the depth of the tree models to be created (i.e., use the parameter <code>nodesize</code> in <code>randomForest</code>).</p>
<p>When a random forest model is built, to make a prediction for a data point, each tree makes a prediction, then all the predictions are combined; e.g., for continuous outcome variable, the average of the predictions is used as the final prediction; for classification outcome variable, the class that wins majority among all trees is the final prediction.</p>
</div>
<div id="r-lab-5" class="section level3 unnumbered">
<h3>R Lab</h3>
<p><em>The 5-Step R Pipeline.</em> <strong>Step 1</strong> and <strong>Step 2</strong> get data into your R work environment and make appropriate preprocessing.</p>
<p></p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1 -&gt; Read data into R workstation</span></span>
<span id="cb90-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="co"># RCurl is the R package to read csv file using a link</span></span>
<span id="cb90-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RCurl)</span>
<span id="cb90-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb90-4" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;https://raw.githubusercontent.com&quot;</span>,</span>
<span id="cb90-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb90-5" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;/analyticsbook/book/main/data/AD.csv&quot;</span>)</span>
<span id="cb90-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb90-6" aria-hidden="true" tabindex="-1"></a>AD <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">text=</span><span class="fu">getURL</span>(url))</span>
<span id="cb90-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="co"># str(AD)</span></span></code></pre></div>
<p></p>
<p></p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2 -&gt; Data preprocessing</span></span>
<span id="cb91-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create your X matrix (predictors) and Y vector </span></span>
<span id="cb91-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-3" aria-hidden="true" tabindex="-1"></a><span class="co"># (outcome variable)</span></span>
<span id="cb91-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-4" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> AD[,<span class="dv">2</span><span class="sc">:</span><span class="dv">16</span>]</span>
<span id="cb91-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-5" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> AD<span class="sc">$</span>DX_bl</span>
<span id="cb91-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-7" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;c&quot;</span>, Y) </span>
<span id="cb91-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-8" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(Y)  </span>
<span id="cb91-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Then, we integrate everything into a data frame</span></span>
<span id="cb91-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-11" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(X,Y)</span>
<span id="cb91-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-12" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(data)[<span class="dv">16</span>] <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;DX_bl&quot;</span>)</span>
<span id="cb91-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a training data (half the original data size)</span></span>
<span id="cb91-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-15" aria-hidden="true" tabindex="-1"></a>train.ix <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(data),<span class="fu">floor</span>( <span class="fu">nrow</span>(data)<span class="sc">/</span><span class="dv">2</span>) )</span>
<span id="cb91-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-16" aria-hidden="true" tabindex="-1"></a>data.train <span class="ot">&lt;-</span> data[train.ix,]</span>
<span id="cb91-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a testing data (half the original data size)</span></span>
<span id="cb91-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb91-18" aria-hidden="true" tabindex="-1"></a>data.test <span class="ot">&lt;-</span> data[<span class="sc">-</span>train.ix,]</span></code></pre></div>
<p></p>
<p><strong>Step 3</strong> uses the R package <code>randomForest</code> to build your random forest model.</p>
<p></p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3 -&gt; Use randomForest() function to build a </span></span>
<span id="cb92-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="co"># RF model </span></span>
<span id="cb92-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="co"># with all predictors</span></span>
<span id="cb92-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb92-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb92-5" aria-hidden="true" tabindex="-1"></a>rf.AD <span class="ot">&lt;-</span> <span class="fu">randomForest</span>( DX_bl <span class="sc">~</span> ., <span class="at">data =</span> data.train, </span>
<span id="cb92-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb92-6" aria-hidden="true" tabindex="-1"></a>                    <span class="at">ntree =</span> <span class="dv">100</span>, <span class="at">nodesize =</span> <span class="dv">20</span>, <span class="at">mtry =</span> <span class="dv">5</span>) </span>
<span id="cb92-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Three main arguments to control the complexity </span></span>
<span id="cb92-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb92-8" aria-hidden="true" tabindex="-1"></a><span class="co"># of a random forest model</span></span></code></pre></div>
<p></p>
<p>Details for the three arguments in <code>randomForest</code>: The <code>ntree</code> is the number of trees<label for="tufte-sn-100" class="margin-toggle sidenote-number">100</label><input type="checkbox" id="tufte-sn-100" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">100</span> The more trees, the more complex the random forest model is.</span>. The <code>nodesize</code> is the minimum sample size of leaf nodes<label for="tufte-sn-101" class="margin-toggle sidenote-number">101</label><input type="checkbox" id="tufte-sn-101" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">101</span> The larger the sample size in leaf nodes, the less depth of the trees; therefore, the less complex the random forest model is.</span>. The <code>mtry</code> is a parameter to control the degree of randomness when your RF model selects variables to split nodes<label for="tufte-sn-102" class="margin-toggle sidenote-number">102</label><input type="checkbox" id="tufte-sn-102" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">102</span> For classification, the default value of <code>mtry</code> is <span class="math inline">\(\sqrt{p}\)</span>, where <span class="math inline">\(p\)</span> is the number of variables; for regression, the default value of <code>mtry</code> is <span class="math inline">\(p/3\)</span>.</span>.</p>
<p><strong>Step 4</strong> is prediction. We use the <code>predict()</code> function</p>
<p></p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4 -&gt; Predict using your RF model</span></span>
<span id="cb93-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb93-2" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.AD, data.test,<span class="at">type=</span><span class="st">&quot;class&quot;</span>)</span></code></pre></div>
<p></p>
<p><strong>Step 5</strong> evaluates the prediction performance of your model on the testing data.</p>
<p></p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5 -&gt; Evaluate the prediction performance of your RF model</span></span>
<span id="cb94-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Three main metrics for classification: Accuracy, </span></span>
<span id="cb94-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Sensitivity (1- False Positive), Specificity (1 - False Negative)</span></span>
<span id="cb94-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb94-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret) </span>
<span id="cb94-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb94-5" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(y_hat, data.test<span class="sc">$</span>DX_bl)</span></code></pre></div>
<p></p>
<p>The result is shown below. It is an information-rich object<label for="tufte-sn-103" class="margin-toggle sidenote-number">103</label><input type="checkbox" id="tufte-sn-103" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">103</span> To learn more about an R object, function, and package, please check out the online documentation that is usually available for an R package that has been released to the public. For example, for the <code>confusionMatrix</code> in the R package <code>caret</code>, check out this link: <a href="https://www.rdocumentation.org/packages/caret/versions/6.0-84/topics/confusionMatrix">https://www.rdocumentation.org/packages/caret/versions/6.0-84/topics/confusionMatrix</a>. Some R packages also come with a journal article published in the <em>Journal of Statistical Software</em>. E.g., for <code>caret</code>, see Kuhn, M., <em>Building predictive models in R using the caret package</em>, Journal of Statistical Software, Volume 28, Issue 5, 2018, <a href="http://www.jstatsoft.org/article/view/v028i05/v28i05.pdf">http://www.jstatsoft.org/article/view/v028i05/v28i05.pdf</a>.</span>.</p>
<p></p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Confusion Matrix and Statistics</span></span>
<span id="cb95-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb95-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-3" aria-hidden="true" tabindex="-1"></a><span class="do">##           Reference</span></span>
<span id="cb95-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Prediction  c0  c1</span></span>
<span id="cb95-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="do">##         c0 136  31</span></span>
<span id="cb95-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="do">##         c1   4  88</span></span>
<span id="cb95-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-7" aria-hidden="true" tabindex="-1"></a><span class="do">##                                          </span></span>
<span id="cb95-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-8" aria-hidden="true" tabindex="-1"></a><span class="do">##                Accuracy : 0.8649         </span></span>
<span id="cb95-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-9" aria-hidden="true" tabindex="-1"></a><span class="do">##                  95% CI : (0.8171, 0.904)</span></span>
<span id="cb95-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-10" aria-hidden="true" tabindex="-1"></a><span class="do">##     No Information Rate : 0.5405         </span></span>
<span id="cb95-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-11" aria-hidden="true" tabindex="-1"></a><span class="do">##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      </span></span>
<span id="cb95-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-12" aria-hidden="true" tabindex="-1"></a><span class="do">##                                          </span></span>
<span id="cb95-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-13" aria-hidden="true" tabindex="-1"></a><span class="do">##                   Kappa : 0.7232         </span></span>
<span id="cb95-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-14" aria-hidden="true" tabindex="-1"></a><span class="do">##                                          </span></span>
<span id="cb95-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-15" aria-hidden="true" tabindex="-1"></a><span class="do">##  Mcnemar&#39;s Test P-Value : 1.109e-05      </span></span>
<span id="cb95-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-16" aria-hidden="true" tabindex="-1"></a><span class="do">##                                          </span></span>
<span id="cb95-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-17" aria-hidden="true" tabindex="-1"></a><span class="do">##             Sensitivity : 0.9714         </span></span>
<span id="cb95-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-18" aria-hidden="true" tabindex="-1"></a><span class="do">##             Specificity : 0.7395         </span></span>
<span id="cb95-19"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-19" aria-hidden="true" tabindex="-1"></a><span class="do">##          Pos Pred Value : 0.8144         </span></span>
<span id="cb95-20"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-20" aria-hidden="true" tabindex="-1"></a><span class="do">##          Neg Pred Value : 0.9565         </span></span>
<span id="cb95-21"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-21" aria-hidden="true" tabindex="-1"></a><span class="do">##              Prevalence : 0.5405         </span></span>
<span id="cb95-22"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-22" aria-hidden="true" tabindex="-1"></a><span class="do">##          Detection Rate : 0.5251         </span></span>
<span id="cb95-23"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-23" aria-hidden="true" tabindex="-1"></a><span class="do">##    Detection Prevalence : 0.6448         </span></span>
<span id="cb95-24"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-24" aria-hidden="true" tabindex="-1"></a><span class="do">##       Balanced Accuracy : 0.8555         </span></span>
<span id="cb95-25"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-25" aria-hidden="true" tabindex="-1"></a><span class="do">##                                          </span></span>
<span id="cb95-26"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb95-26" aria-hidden="true" tabindex="-1"></a><span class="do">##        &#39;Positive&#39; Class : c0 </span></span></code></pre></div>
<p></p>
<p>We can also draw the ROC curve</p>
<p></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC curve is another commonly reported metric </span></span>
<span id="cb96-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="co"># for classification models</span></span>
<span id="cb96-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC) </span>
<span id="cb96-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-4" aria-hidden="true" tabindex="-1"></a><span class="co"># pROC has the roc() function that is very useful here</span></span>
<span id="cb96-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-5" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf.AD, data.test,<span class="at">type=</span><span class="st">&quot;vote&quot;</span>) </span>
<span id="cb96-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-6" aria-hidden="true" tabindex="-1"></a><span class="co"># In order to draw ROC, we need the intermediate prediction </span></span>
<span id="cb96-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-7" aria-hidden="true" tabindex="-1"></a><span class="co"># (before RF model binarize it into binary classification). </span></span>
<span id="cb96-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Thus, by specifying the argument type=&quot;vote&quot;, we can </span></span>
<span id="cb96-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-9" aria-hidden="true" tabindex="-1"></a><span class="co"># generate this intermediate prediction. y_hat now has </span></span>
<span id="cb96-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-10" aria-hidden="true" tabindex="-1"></a><span class="co"># two columns, one corresponds to the ratio of votes the </span></span>
<span id="cb96-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-11" aria-hidden="true" tabindex="-1"></a><span class="co"># trees assign to one class, and the other column is the </span></span>
<span id="cb96-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-12" aria-hidden="true" tabindex="-1"></a><span class="co"># ratio of votes the trees assign to another class.</span></span>
<span id="cb96-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-13" aria-hidden="true" tabindex="-1"></a>main <span class="ot">=</span> <span class="st">&quot;ROC Curve&quot;</span></span>
<span id="cb96-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">roc</span>(data.test<span class="sc">$</span>DX_bl, y_hat[,<span class="dv">1</span>]),</span>
<span id="cb96-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb96-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">col=</span><span class="st">&quot;blue&quot;</span>, <span class="at">main=</span>main)</span></code></pre></div>
<p></p>
<p>And we can have the ROC curve as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-RF-ROC">71</a>.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-RF-ROC"></span>
<img src="graphics/4_RF_ROC.png" alt="ROC curve of the RF model" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 71: ROC curve of the RF model<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p><em>Beyond the 5-Step R Pipeline.</em> Random forests are complex models that have many parameters to be tuned. In <strong>Chapter 2</strong> and <strong>Chapter 3</strong> we have used the <code>step()</code> function for automatic model selection for regression models. Part of the reason this is possible for regression models is that model selection for regression models largely concerns variable selection only. For decision tree and random forest models, the model selection concerns not only variable selection, but also many other aspects, such as the depth of the tree, the number of trees, and the degree of randomness that would be used in model training. This makes the model selection for tree models a craft. An individual’s experience and insights make a difference, and some may find a better model, even the same package is used on the same dataset to build models<label for="tufte-sn-104" class="margin-toggle sidenote-number">104</label><input type="checkbox" id="tufte-sn-104" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">104</span> There is often an impression that a good model is built by a good pipeline, like this 5-step pipeline. This impression is a reductive view, since it only looks at the final stage of data analytics. Like manufacturing, when the process is mature and we are able to see the rationale behind every detail of the manufacturing process, we may lose sight of those alternatives that had been considered, experimented, then discarded (or withheld) for various reasons.</span>.</p>
<p>To see how these parameters impact the models, we conduct some experiments. The number of trees is one of the most important parameters of random forests that we’d like to be tuned well. We can build different random forest models by tuning the parameter <code>ntree</code> in <code>randomForest</code>. For each selection of the number of trees, we first randomly split the dataset into training and testing datasets, then train the model on the training dataset, and evaluate its performance on the testing dataset. This process of data splitting, model training, and testing is repeated <span class="math inline">\(100\)</span> times. We can use boxplots to show the overall performance of the models. Results are shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-21">72</a>.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-21"></span>
<img src="graphics/4_21.png" alt="Error v.s. number of trees in a random forest model" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 72: Error v.s. number of trees in a random forest model<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p></p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb97-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb97-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb97-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb97-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-5" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(randomForest)</span>
<span id="cb97-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RCurl)</span>
<span id="cb97-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb97-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-9" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_gray</span>(<span class="at">base_size =</span> <span class="dv">15</span>))</span>
<span id="cb97-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-10" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;https://raw.githubusercontent.com&quot;</span>,</span>
<span id="cb97-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-11" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;/analyticsbook/book/main/data/AD.csv&quot;</span>)</span>
<span id="cb97-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-12" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">text=</span><span class="fu">getURL</span>(url))</span>
<span id="cb97-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-14" aria-hidden="true" tabindex="-1"></a>target_indx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">==</span> <span class="st">&quot;DX_bl&quot;</span>)</span>
<span id="cb97-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-15" aria-hidden="true" tabindex="-1"></a>data[, target_indx] <span class="ot">&lt;-</span> </span>
<span id="cb97-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.factor</span>(<span class="fu">paste0</span>(<span class="st">&quot;c&quot;</span>, data[, target_indx]))</span>
<span id="cb97-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-17" aria-hidden="true" tabindex="-1"></a>rm_indx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;ID&quot;</span>, <span class="st">&quot;TOTAL13&quot;</span>,</span>
<span id="cb97-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-18" aria-hidden="true" tabindex="-1"></a>                                       <span class="st">&quot;MMSCORE&quot;</span>))</span>
<span id="cb97-19"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-19" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data[, <span class="sc">-</span>rm_indx]</span>
<span id="cb97-20"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-20" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb97-21"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (itree <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">400</span>, <span class="dv">500</span>,</span>
<span id="cb97-22"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-22" aria-hidden="true" tabindex="-1"></a>    <span class="dv">600</span>, <span class="dv">700</span>)) {</span>
<span id="cb97-23"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) {</span>
<span id="cb97-24"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-24" aria-hidden="true" tabindex="-1"></a>train.ix <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(data), <span class="fu">floor</span>(<span class="fu">nrow</span>(data)<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb97-25"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-25" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(DX_bl <span class="sc">~</span> ., <span class="at">ntree =</span> itree, <span class="at">data =</span></span>
<span id="cb97-26"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-26" aria-hidden="true" tabindex="-1"></a>                                        data[train.ix, ])</span>
<span id="cb97-27"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-27" aria-hidden="true" tabindex="-1"></a>pred.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, data[<span class="sc">-</span>train.ix, ], <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb97-28"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-28" aria-hidden="true" tabindex="-1"></a>this.err <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(pred.test <span class="sc">!=</span></span>
<span id="cb97-29"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-29" aria-hidden="true" tabindex="-1"></a>                data[<span class="sc">-</span>train.ix, ]<span class="sc">$</span>DX_bl))<span class="sc">/</span><span class="fu">length</span>(pred.test)</span>
<span id="cb97-30"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-30" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(results, <span class="fu">c</span>(itree, this.err))</span>
<span id="cb97-31"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-31" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb97-32"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb97-33"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-34"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-34" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(results) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;num_trees&quot;</span>, <span class="st">&quot;error&quot;</span>)</span>
<span id="cb97-35"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-35" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(results) <span class="sc">%&gt;%</span></span>
<span id="cb97-36"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">num_trees =</span> <span class="fu">as.character</span>(num_trees))</span>
<span id="cb97-37"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-37" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(results<span class="sc">$</span>num_trees) <span class="ot">&lt;-</span> <span class="fu">unique</span>(results<span class="sc">$</span>num_trees)</span>
<span id="cb97-38"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-38" aria-hidden="true" tabindex="-1"></a>results<span class="sc">$</span>num_trees <span class="ot">&lt;-</span> <span class="fu">factor</span>(results<span class="sc">$</span>num_trees,</span>
<span id="cb97-39"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-39" aria-hidden="true" tabindex="-1"></a>                            <span class="fu">unique</span>(results<span class="sc">$</span>num_trees))</span>
<span id="cb97-40"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-40" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">geom_boxplot</span>(<span class="at">data =</span> results, <span class="fu">aes</span>(<span class="at">y =</span> error,</span>
<span id="cb97-41"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb97-41" aria-hidden="true" tabindex="-1"></a>                <span class="at">x =</span> num_trees)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>)</span></code></pre></div>
<p></p>
<p>It can be seen in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-21">72</a> that when the number of trees is small, particularly, less than <span class="math inline">\(10\)</span>, the improvement on prediction performance of random forest is substantial with trees added. However, the error rates become stable after the number of trees reaches <span class="math inline">\(100\)</span>.</p>
<p>Next, let’s consider the number of features (i.e., use the parameter <code>mtry</code> in the function <code>randomForest</code>). Here, <span class="math inline">\(100\)</span> trees are used. For each number of features, again, following the process we have used in the experiment with the number of trees, we draw the boxplots in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-22">73</a>.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-22"></span>
<img src="graphics/4_22.png" alt="Error v.s. number of features in a random forest model" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 73: Error v.s. number of features in a random forest model<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>It can be seen that the error rates are not significantly different when the number of features changes.</p>
<p></p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb98-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb98-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb98-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb98-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-5" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(randomForest)</span>
<span id="cb98-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RCurl)</span>
<span id="cb98-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb98-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-8" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_gray</span>(<span class="at">base_size =</span> <span class="dv">15</span>))</span>
<span id="cb98-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-10" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;https://raw.githubusercontent.com&quot;</span>,</span>
<span id="cb98-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-11" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;/analyticsbook/book/main/data/AD.csv&quot;</span>)</span>
<span id="cb98-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-12" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">text=</span><span class="fu">getURL</span>(url))</span>
<span id="cb98-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-14" aria-hidden="true" tabindex="-1"></a>target_indx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">==</span> <span class="st">&quot;DX_bl&quot;</span>)</span>
<span id="cb98-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-15" aria-hidden="true" tabindex="-1"></a>data[, target_indx] <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(</span>
<span id="cb98-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-16" aria-hidden="true" tabindex="-1"></a>        <span class="fu">paste0</span>(<span class="st">&quot;c&quot;</span>, data[, target_indx]))</span>
<span id="cb98-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-17" aria-hidden="true" tabindex="-1"></a>rm_indx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;ID&quot;</span>, <span class="st">&quot;TOTAL13&quot;</span>,</span>
<span id="cb98-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-18" aria-hidden="true" tabindex="-1"></a>                                       <span class="st">&quot;MMSCORE&quot;</span>))</span>
<span id="cb98-19"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-19" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data[, <span class="sc">-</span>rm_indx]</span>
<span id="cb98-20"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-20" aria-hidden="true" tabindex="-1"></a>nFea <span class="ot">&lt;-</span> <span class="fu">ncol</span>(data) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb98-21"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-21" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb98-22"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (iFeatures <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nFea) {</span>
<span id="cb98-23"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) {</span>
<span id="cb98-24"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-24" aria-hidden="true" tabindex="-1"></a>train.ix <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(data), <span class="fu">floor</span>(<span class="fu">nrow</span>(data)<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb98-25"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-25" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(DX_bl <span class="sc">~</span> ., <span class="at">mtry =</span> iFeatures, <span class="at">ntree =</span> <span class="dv">100</span>,</span>
<span id="cb98-26"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-26" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> data[train.ix,])</span>
<span id="cb98-27"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-27" aria-hidden="true" tabindex="-1"></a>pred.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, data[<span class="sc">-</span>train.ix, ], <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb98-28"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-28" aria-hidden="true" tabindex="-1"></a>this.err <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(pred.test <span class="sc">!=</span></span>
<span id="cb98-29"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-29" aria-hidden="true" tabindex="-1"></a>                 data[<span class="sc">-</span>train.ix, ]<span class="sc">$</span>DX_bl))<span class="sc">/</span><span class="fu">length</span>(pred.test)</span>
<span id="cb98-30"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-30" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(results, <span class="fu">c</span>(iFeatures, this.err))</span>
<span id="cb98-31"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-31" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb98-32"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb98-33"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-33" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(results) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;num_features&quot;</span>, <span class="st">&quot;error&quot;</span>)</span>
<span id="cb98-34"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-34" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(results) <span class="sc">%&gt;%</span></span>
<span id="cb98-35"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">num_features =</span> <span class="fu">as.character</span>(num_features))</span>
<span id="cb98-36"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-36" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(results<span class="sc">$</span>num_features) <span class="ot">&lt;-</span> <span class="fu">unique</span>(results<span class="sc">$</span>num_features)</span>
<span id="cb98-37"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-37" aria-hidden="true" tabindex="-1"></a>results<span class="sc">$</span>num_features <span class="ot">&lt;-</span> <span class="fu">factor</span>(results<span class="sc">$</span>num_features,</span>
<span id="cb98-38"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-38" aria-hidden="true" tabindex="-1"></a>                              <span class="fu">unique</span>(results<span class="sc">$</span>num_features))</span>
<span id="cb98-39"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-39" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">geom_boxplot</span>(<span class="at">data =</span> results, <span class="fu">aes</span>(<span class="at">y =</span> error,</span>
<span id="cb98-40"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb98-40" aria-hidden="true" tabindex="-1"></a>                  <span class="at">x =</span> num_features)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>)</span></code></pre></div>
<p></p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-23"></span>
<img src="graphics/4_23.png" alt="Error v.s. node size in a random forest model" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 74: Error v.s. node size in a random forest model<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>Further, we experiment with the minimum node size (i.e., use the parameter <code>nodesize</code> in the function <code>randomForest</code>), that is, the minimum number of instances at a node. Boxplots of their performances are shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-23">74</a>.</p>
<p></p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb99-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb99-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb99-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-4" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(randomForest)</span>
<span id="cb99-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RCurl)</span>
<span id="cb99-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb99-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-8" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_gray</span>(<span class="at">base_size =</span> <span class="dv">15</span>))</span>
<span id="cb99-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-10" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;https://raw.githubusercontent.com&quot;</span>,</span>
<span id="cb99-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-11" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;/analyticsbook/book/main/data/AD.csv&quot;</span>)</span>
<span id="cb99-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-13" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">text=</span><span class="fu">getURL</span>(url))</span>
<span id="cb99-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-15" aria-hidden="true" tabindex="-1"></a>target_indx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">==</span> <span class="st">&quot;DX_bl&quot;</span>)</span>
<span id="cb99-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-16" aria-hidden="true" tabindex="-1"></a>data[, target_indx] <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">paste0</span>(<span class="st">&quot;c&quot;</span>, data[, target_indx]))</span>
<span id="cb99-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-17" aria-hidden="true" tabindex="-1"></a>rm_indx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;ID&quot;</span>, <span class="st">&quot;TOTAL13&quot;</span>,</span>
<span id="cb99-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-18" aria-hidden="true" tabindex="-1"></a>                                       <span class="st">&quot;MMSCORE&quot;</span>))</span>
<span id="cb99-19"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-19" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data[, <span class="sc">-</span>rm_indx]</span>
<span id="cb99-20"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-21"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-21" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb99-22"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (inodesize <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>,</span>
<span id="cb99-23"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-23" aria-hidden="true" tabindex="-1"></a>    <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>, <span class="dv">70</span>, <span class="dv">80</span>,<span class="dv">90</span>, <span class="dv">100</span>)) {</span>
<span id="cb99-24"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-24" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) {</span>
<span id="cb99-25"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-25" aria-hidden="true" tabindex="-1"></a>    train.ix <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(data), <span class="fu">floor</span>(<span class="fu">nrow</span>(data)<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb99-26"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-26" aria-hidden="true" tabindex="-1"></a>    rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(DX_bl <span class="sc">~</span> ., <span class="at">ntree =</span> <span class="dv">100</span>, <span class="at">nodesize =</span></span>
<span id="cb99-27"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-27" aria-hidden="true" tabindex="-1"></a>                     inodesize, <span class="at">data =</span> data[train.ix,])</span>
<span id="cb99-28"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-28" aria-hidden="true" tabindex="-1"></a>    pred.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, data[<span class="sc">-</span>train.ix, ], <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb99-29"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-29" aria-hidden="true" tabindex="-1"></a>    this.err <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">which</span>(pred.test <span class="sc">!=</span></span>
<span id="cb99-30"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-30" aria-hidden="true" tabindex="-1"></a>                    data[<span class="sc">-</span>train.ix, ]<span class="sc">$</span>DX_bl))<span class="sc">/</span><span class="fu">length</span>(pred.test)</span>
<span id="cb99-31"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-31" aria-hidden="true" tabindex="-1"></a>    results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(results, <span class="fu">c</span>(inodesize, this.err))</span>
<span id="cb99-32"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># err.rf &lt;- c(err.rf, length(which(pred.test !=</span></span>
<span id="cb99-33"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># data[-train.ix,]$DX_bl))/length(pred.test) )</span></span>
<span id="cb99-34"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-34" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb99-35"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb99-36"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-37"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-37" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(results) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;min_node_size&quot;</span>, <span class="st">&quot;error&quot;</span>)</span>
<span id="cb99-38"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-38" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(results) <span class="sc">%&gt;%</span></span>
<span id="cb99-39"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">min_node_size =</span> <span class="fu">as.character</span>(min_node_size))</span>
<span id="cb99-40"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-40" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(results<span class="sc">$</span>min_node_size) <span class="ot">&lt;-</span> <span class="fu">unique</span>(results<span class="sc">$</span>min_node_size)</span>
<span id="cb99-41"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-41" aria-hidden="true" tabindex="-1"></a>results<span class="sc">$</span>min_node_size <span class="ot">&lt;-</span> <span class="fu">factor</span>(results<span class="sc">$</span>min_node_size,</span>
<span id="cb99-42"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-42" aria-hidden="true" tabindex="-1"></a>                                <span class="fu">unique</span>(results<span class="sc">$</span>min_node_size))</span>
<span id="cb99-43"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-43" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">geom_boxplot</span>(<span class="at">data =</span> results, <span class="fu">aes</span>(<span class="at">y =</span> error,</span>
<span id="cb99-44"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb99-44" aria-hidden="true" tabindex="-1"></a>                  <span class="at">x =</span> min_node_size)) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>)</span></code></pre></div>
<p></p>
<div style="page-break-after: always;"></div>
<p>Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-23">74</a> shows that the error rates start to rise when the minimum node size equals 40. And the error rates are not substantially different when the minimum node size is less than 40. All together, these results provide information for us to select models.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-20"></span>
<img src="graphics/4_20.png" alt="Performance of random forest v.s. tree model on the Alzheimer's disease data" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 75: Performance of random forest v.s. tree model on the Alzheimer’s disease data<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>To compare random forest with decision tree, we can also follow a similar process, i.e., half of the dataset is used for training and the other half for testing. This process of splitting data, training the model on training data, and testing the model on testing data is repeated <span class="math inline">\(100\)</span> times, and boxplots of the errors from decision trees and random forests are plotted in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-20">75</a> using the following R code.</p>
<p></p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb100-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb100-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb100-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb100-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(RCurl)</span>
<span id="cb100-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-6" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(randomForest)</span>
<span id="cb100-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb100-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-9" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_gray</span>(<span class="at">base_size =</span> <span class="dv">15</span>))</span>
<span id="cb100-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-11" aria-hidden="true" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;https://raw.githubusercontent.com&quot;</span>,</span>
<span id="cb100-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-12" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;/analyticsbook/book/main/data/AD.csv&quot;</span>)</span>
<span id="cb100-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-13" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="at">text=</span><span class="fu">getURL</span>(url))</span>
<span id="cb100-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-15"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-15" aria-hidden="true" tabindex="-1"></a>target_indx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">==</span> <span class="st">&quot;DX_bl&quot;</span>)</span>
<span id="cb100-16"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-16" aria-hidden="true" tabindex="-1"></a>data[, target_indx] <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">paste0</span>(<span class="st">&quot;c&quot;</span>, data[, target_indx]))</span>
<span id="cb100-17"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-17" aria-hidden="true" tabindex="-1"></a>rm_indx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">colnames</span>(data) <span class="sc">%in%</span> </span>
<span id="cb100-18"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-18" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">c</span>(<span class="st">&quot;ID&quot;</span>, <span class="st">&quot;TOTAL13&quot;</span>, <span class="st">&quot;MMSCORE&quot;</span>))</span>
<span id="cb100-19"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-19" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> data[, <span class="sc">-</span>rm_indx]</span>
<span id="cb100-20"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-21"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-21" aria-hidden="true" tabindex="-1"></a>err.tree <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb100-22"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-22" aria-hidden="true" tabindex="-1"></a>err.rf <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb100-23"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>) {</span>
<span id="cb100-24"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-24" aria-hidden="true" tabindex="-1"></a>train.ix <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(data), <span class="fu">floor</span>(<span class="fu">nrow</span>(data)<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb100-25"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-25" aria-hidden="true" tabindex="-1"></a>tree <span class="ot">&lt;-</span> <span class="fu">rpart</span>(DX_bl <span class="sc">~</span> ., <span class="at">data =</span> data[train.ix, ])</span>
<span id="cb100-26"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-26" aria-hidden="true" tabindex="-1"></a>pred.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree, data[<span class="sc">-</span>train.ix, ], <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb100-27"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-27" aria-hidden="true" tabindex="-1"></a>err.tree <span class="ot">&lt;-</span> <span class="fu">c</span>(err.tree, <span class="fu">length</span>(</span>
<span id="cb100-28"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which</span>(pred.test <span class="sc">!=</span> data[<span class="sc">-</span>train.ix, ]<span class="sc">$</span>DX_bl))<span class="sc">/</span><span class="fu">length</span>(pred.test))</span>
<span id="cb100-29"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-30"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-30" aria-hidden="true" tabindex="-1"></a>rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(DX_bl <span class="sc">~</span> ., <span class="at">data =</span> data[train.ix, ])</span>
<span id="cb100-31"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-31" aria-hidden="true" tabindex="-1"></a>pred.test <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf, data[<span class="sc">-</span>train.ix, ], <span class="at">type =</span> <span class="st">&quot;class&quot;</span>)</span>
<span id="cb100-32"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-32" aria-hidden="true" tabindex="-1"></a>err.rf <span class="ot">&lt;-</span> <span class="fu">c</span>(err.rf, <span class="fu">length</span>(</span>
<span id="cb100-33"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">which</span>(pred.test <span class="sc">!=</span> data[<span class="sc">-</span>train.ix, ]<span class="sc">$</span>DX_bl))<span class="sc">/</span><span class="fu">length</span>(pred.test))</span>
<span id="cb100-34"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb100-35"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-35" aria-hidden="true" tabindex="-1"></a>err.tree <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">err =</span> err.tree, <span class="at">method =</span> <span class="st">&quot;tree&quot;</span>)</span>
<span id="cb100-36"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-36" aria-hidden="true" tabindex="-1"></a>err.rf <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">err =</span> err.rf, <span class="at">method =</span> <span class="st">&quot;random_forests&quot;</span>)</span>
<span id="cb100-37"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-38"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-38" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">geom_boxplot</span>(</span>
<span id="cb100-39"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-39" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> <span class="fu">rbind</span>(err.tree, err.rf), <span class="fu">aes</span>(<span class="at">y =</span> err, <span class="at">x =</span> method)) <span class="sc">+</span> </span>
<span id="cb100-40"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb100-40" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>)</span></code></pre></div>
<p></p>
<p>Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-20">75</a> shows that the error rates of decision trees are higher than those for random forests, indicating that random forest is a better model here.</p>
</div>
</div>
<div id="remarks-2" class="section level2 unnumbered">
<h2>Remarks</h2>
<div id="the-gini-index-versus-the-entropy" class="section level3 unnumbered">
<h3>The Gini index versus the entropy</h3>
<p>The <em>Gini index</em> plays the same role as the <em>entropy</em>. To see that, the following R code plots the Gini index and the entropy in a binary class problem<label for="tufte-sn-105" class="margin-toggle sidenote-number">105</label><input type="checkbox" id="tufte-sn-105" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">105</span> A binary class problem has two nominal parameters, <span class="math inline">\(p_{1}\)</span> and <span class="math inline">\(p_{2}\)</span>. Because <span class="math inline">\(p_{2}\)</span> equals <span class="math inline">\(1-p_{1}\)</span>, it is actually a one-parameter system, such that we can visualize how the Gini index and the entropy changes according to <span class="math inline">\(p_{1}\)</span>, as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-15">76</a>.</span>. Their similarity is evident as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-15">76</a>.</p>
<p>The following R scripts package the Gini index and entropy as two functions.</p>
<p></p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-1" aria-hidden="true" tabindex="-1"></a>entropy <span class="ot">&lt;-</span> <span class="cf">function</span>(p_v) {</span>
<span id="cb101-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-2" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb101-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (p <span class="cf">in</span> p_v) {</span>
<span id="cb101-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (p <span class="sc">==</span> <span class="dv">0</span>) {</span>
<span id="cb101-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-5" aria-hidden="true" tabindex="-1"></a>this_term <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb101-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-6" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb101-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-7" aria-hidden="true" tabindex="-1"></a>this_term <span class="ot">&lt;-</span> <span class="sc">-</span>p <span class="sc">*</span> <span class="fu">log2</span>(p)</span>
<span id="cb101-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb101-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-9" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> e <span class="sc">+</span> this_term</span>
<span id="cb101-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb101-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-11" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(e)</span>
<span id="cb101-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb101-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p></p>
<p></p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-1" aria-hidden="true" tabindex="-1"></a>gini <span class="ot">&lt;-</span> <span class="cf">function</span>(p_v) {</span>
<span id="cb102-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-2" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb102-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (p <span class="cf">in</span> p_v) {</span>
<span id="cb102-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (p <span class="sc">==</span> <span class="dv">0</span>) {</span>
<span id="cb102-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-5" aria-hidden="true" tabindex="-1"></a>this.term <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb102-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-6" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb102-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-7" aria-hidden="true" tabindex="-1"></a>this.term <span class="ot">&lt;-</span> p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p)</span>
<span id="cb102-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb102-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-9" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> e <span class="sc">+</span> this.term</span>
<span id="cb102-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb102-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-11" aria-hidden="true" tabindex="-1"></a><span class="fu">return</span>(e)</span>
<span id="cb102-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb102-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p></p>
<p>The following R script draws Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-15">76</a>.</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f4-15"></span>
<img src="graphics/4_15.png" alt="Gini index vs. entropy" width="100%"  />
<!--
<p class="caption marginnote">-->Figure 76: Gini index vs. entropy<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p></p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-1" aria-hidden="true" tabindex="-1"></a>entropy.v <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb103-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-2" aria-hidden="true" tabindex="-1"></a>gini.v <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb103-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-3" aria-hidden="true" tabindex="-1"></a>p.v <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb103-4"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (p <span class="cf">in</span> p.v) {</span>
<span id="cb103-5"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-5" aria-hidden="true" tabindex="-1"></a>entropy.v <span class="ot">&lt;-</span> <span class="fu">c</span>(entropy.v, (<span class="fu">entropy</span>(<span class="fu">c</span>(p, <span class="dv">1</span> <span class="sc">-</span> p))))</span>
<span id="cb103-6"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-6" aria-hidden="true" tabindex="-1"></a>gini.v <span class="ot">&lt;-</span> <span class="fu">c</span>(gini.v, (<span class="fu">gini</span>(<span class="fu">c</span>(p, <span class="dv">1</span> <span class="sc">-</span> p))))</span>
<span id="cb103-7"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb103-8"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p.v, gini.v, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb103-9"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;percentage of class 1&quot;</span>,<span class="at">col =</span> <span class="st">&quot;red&quot;</span>,</span>
<span id="cb103-10"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;impurity measure&quot;</span>, <span class="at">cex.lab =</span> <span class="fl">1.5</span>,</span>
<span id="cb103-11"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex.axis =</span> <span class="fl">1.5</span>, <span class="at">cex.main =</span> <span class="fl">1.5</span>,<span class="at">cex.sub =</span> <span class="fl">1.5</span>)</span>
<span id="cb103-12"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-12" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(p.v, entropy.v, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb103-13"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-13" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&quot;Entropy&quot;</span>, <span class="st">&quot;Gini index&quot;</span>),</span>
<span id="cb103-14"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb103-14" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="at">cex =</span> <span class="fl">0.8</span>)</span></code></pre></div>
<p></p>
<p>It can be seen in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-15">76</a> that the two impurity measures are similar. Both reach minimum, i.e., <span class="math inline">\(0\)</span>, when all the data instances belong to the same class, and they reach maximum when there are equal numbers of data instances for the two classes. In practice, they produce similar trees.</p>
</div>
<div id="why-random-forests-work" class="section level3 unnumbered">
<h3>Why random forests work</h3>
<p>A random forest model is inspirational because it shows that <em>randomness</em>, usually considered as a troublemaker, has a productive dimension. This seems to be counterintuitive. An explanation has been pointed out in numerous literature that the random forests, together with other models that are called <strong>ensemble learning</strong> models, could make a group of <strong>weak models</strong> come together to form a strong model.</p>
<p>For example, consider a random forest model with <span class="math inline">\(100\)</span> trees. Each tree is a <em>weak model</em> and its accuracy is <span class="math inline">\(0.6\)</span>. Assume that the trees are independent<label for="tufte-sn-106" class="margin-toggle sidenote-number">106</label><input type="checkbox" id="tufte-sn-106" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">106</span> I.e., the predictions of one tree provide no hint to guess the predictions of another tree.</span>, with <span class="math inline">\(100\)</span> trees the probability of the random forest model to predict correctly on any data point is <span class="math inline">\(0.97\)</span>, i.e.,</p>
<p><span class="math display">\[\begin{equation*}
\small
   
\sum_{k=51}^{100} C(n, k) \times 0.6^{k} \times 0.4^{100-k} = 0.97. 
 
\end{equation*}\]</span></p>
<p>This result is impressive, but don’t forget the <em>assumption of the independence</em> between the trees. This assumption does not hold in reality in a strict sense; i.e., ideally, we hope to have an algorithm that can find many good models that perform well and are all different; but, if we build many models using one dataset, these models would more or less resemble each other. Particularly, when we solely focus on models that can achieve optimal performance, it is often that the identified models end up more or less the same. Responding to this dilemma, randomness (i.e., the use of Bootstrap to randomize choices of data instances and the use of random feature selection for building trees) is introduced into the model-building process to create diversity of the models. The dynamics between the degree of randomness, the performance of each individual model, and their difference, should be handled well. To develop the craft, you may have many practices and focus on driving this dynamics towards a collective good.</p>
</div>
<div id="variable-importance-by-random-forests" class="section level3 unnumbered">
<h3>Variable importance by random forests</h3>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f8-18"></span>
<img src="graphics/8_18.png" alt="Tree \#1" width="60%"  />
<!--
<p class="caption marginnote">-->Figure 77: Tree #1<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p>Recall that a random forest model consists of decision trees that are defined by splits on some variables. The splits provide information about variables’ importance. To explain this, consider the data example shown in Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t8-3">12</a>.</p>
<p></p>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:t8-3">Table 12: </span>Example of a dataset</span><!--</caption>--></p>
<table>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left"><span class="math inline">\(x_1\)</span></th>
<th align="left"><span class="math inline">\(x_2\)</span></th>
<th align="left"><span class="math inline">\(x_3\)</span></th>
<th align="left"><span class="math inline">\(x_4\)</span></th>
<th align="left">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C0\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(2\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(3\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(4\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
</tbody>
</table>
<p></p>
<p>Assume that a random forest model with two trees (i.e., shown in Figures <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f8-18">77</a> and <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f8-19">78</a>) is built on the dataset.</p>
<p>At split 1, the Gini gain for <span class="math inline">\(x_1\)</span> is:</p>
<p><span class="math display">\[\begin{equation*}
\small
  0.375-0.5\times0-0.5\times0.5 = 0.125. 
\end{equation*}\]</span></p>
<p>At split 2, the Gini gain for <span class="math inline">\(x_3\)</span> is:</p>
<p></p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span style="display:block;" id="fig:f8-19"></span>
<img src="graphics/8_19.png" alt="Tree \#2" width="60%"  />
<!--
<p class="caption marginnote">-->Figure 78: Tree #2<!--</p>-->
<!--</div>--></span>
</p>
<p></p>
<p><span class="math display">\[\begin{equation*}
\small
  0.5-0.5\times0-0.5\times0 = 0.5. 
\end{equation*}\]</span></p>
<p>At split 3, the Gini gain for <span class="math inline">\(x_2\)</span> is</p>
<p><span class="math display">\[\begin{equation*}
\small
  0.5-0.25\times0 + 0.75\times0.44 = 0.17. 
\end{equation*}\]</span></p>
<p>At split 4, the Gini gain for <span class="math inline">\(x_3\)</span> is</p>
<p><span class="math display">\[\begin{equation*}
\small
  0.44-0.5\times0 + 0.5\times0 = 0.44. 
\end{equation*}\]</span></p>
<p>Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t8-scoresheet">13</a> summarizes the contributions of the variables in the splits. The total contribution can be used as the variable’s importance score.</p>
<p></p>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:t8-scoresheet">Table 13: </span>Contributions of the variables in the splits</span><!--</caption>--></p>
<table>
<thead>
<tr class="header">
<th align="left">ID of splits</th>
<th align="left"><span class="math inline">\(x_1\)</span></th>
<th align="left"><span class="math inline">\(x_2\)</span></th>
<th align="left"><span class="math inline">\(x_3\)</span></th>
<th align="left"><span class="math inline">\(x_4\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(0.125\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(2\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0.5\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(3\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0.17\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(4\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0.44\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(Total\)</span></td>
<td align="left"><span class="math inline">\(0.125\)</span></td>
<td align="left"><span class="math inline">\(0.17\)</span></td>
<td align="left"><span class="math inline">\(0.94\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
</tr>
</tbody>
</table>
<p></p>
<p>The variable’s importance score helps us identify the variables that have strong predictive values. The approach to obtain the variable’s importance score is simple and effective, but it is not perfect. For example, if we revisit the example shown in Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t8-3">12</a>, we may notice that <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are identical. What does this suggest to you<label for="tufte-sn-107" class="margin-toggle sidenote-number">107</label><input type="checkbox" id="tufte-sn-107" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">107</span> Interested readers may read this article: Deng, H. and Runger, G., <em>Gene selection with guided regularized random forest</em>, Pattern Recognition, Volume 46, Issue 12, Pages 3483-3489, 2013.</span>?</p>
</div>
<div id="partial-dependency-plot" class="section level3 unnumbered">
<h3>Partial dependency plot</h3>
<p>Variable importance scores indicate whether a variable is informative in predicting the outcome variable. It does not provide information about <em>how</em> the outcome variable is influenced by the variables. <strong>Partial dependency plot</strong> can be used to visualize the relationship between a predictor and the outcome variable, averaged on other predictors.</p>
<p></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:f6-7"></span>
<p class="caption marginnote shownote">
Figure 79: Partial dependency plots of variables in random forests
</p>
<img src="graphics/6_7.png" alt="Partial dependency plots of variables in random forests" width="80%"  />
</div>
<p></p>
<p>We draw in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f6-7">79</a> the partial dependency plots of two variables on the AD dataset. It is clear that the relationships between the outcome variable with both predictors are significant. And the orientation of both relationships is visualized by the plots.</p>
<p></p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the partial dependency plots of variables in random forests </span></span>
<span id="cb104-2"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb104-2" aria-hidden="true" tabindex="-1"></a>randomForest<span class="sc">::</span><span class="fu">partialPlot</span>(rf, data, HippoNV, <span class="st">&quot;1&quot;</span>)</span>
<span id="cb104-3"><a href="chapter-4.-resonance-bootstrap-random-forests.html#cb104-3" aria-hidden="true" tabindex="-1"></a>randomForest<span class="sc">::</span><span class="fu">partialPlot</span>(rf, data, FDG, <span class="st">&quot;1&quot;</span>)</span></code></pre></div>
<p></p>
</div>
</div>
<div id="exercises-2" class="section level2 unnumbered">
<h2>Exercises</h2>
<p><!-- begin{enumerate} --></p>
<p>1. Continue the example in the 4-step R pipeline R lab in this chapter that estimated the mean and standard derivation of the variable <code>HippoNV</code> of the AD dataset. Use the same R pipeline to evaluate the uncertainty of the estimation of the standard derivation of the variable <code>HippoNV</code> of the AD dataset. Report its <span class="math inline">\(95\%\)</span> CI.</p>
<p>2. Use the R pipeline for Bootstrap to evaluate the uncertainty of the estimation of the coefficient of a logistic regression model. Report the <span class="math inline">\(95\%\)</span> CI of the estimated coefficients.</p>
<p></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:f4-rf-2trees"></span>
<p class="caption marginnote shownote">
Figure 80: A random forest model with <span class="math inline">\(2\)</span> trees
</p>
<img src="graphics/4_rf_2trees.png" alt="A random forest model with $2$ trees" width="80%"  />
</div>
<p></p>
<p>3. Consider the data in Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t4-hw-rf-imp">14</a>. Assume that two trees were built on it, as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-rf-2trees">80</a>. (a) Calculate the Gini index of each node of both trees; and (b) estimate the importance scores of the three variables in this RF model.</p>
<p></p>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:t4-hw-rf-imp">Table 14: </span>Dataset for Q3</span><!--</caption>--></p>
<table>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left"><span class="math inline">\(x_1\)</span></th>
<th align="left"><span class="math inline">\(x_2\)</span></th>
<th align="left"><span class="math inline">\(x_3\)</span></th>
<th align="left">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C0\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(2\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(3\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(4\)</span></td>
<td align="left"><span class="math inline">\(0\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(C1\)</span></td>
</tr>
</tbody>
</table>
<p></p>
<p></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:f4-rf-3trees"></span>
<p class="caption marginnote shownote">
Figure 81: A random forest model with <span class="math inline">\(3\)</span> trees
</p>
<img src="graphics/4_rf_3trees.png" alt="A random forest model with $3$ trees" width="80%"  />
</div>
<p></p>
<p>4. A random forest model with <span class="math inline">\(3\)</span> trees is built, as shown in Figure <a href="chapter-4.-resonance-bootstrap-random-forests.html#fig:f4-rf-3trees">81</a>. Use this model to predict on the data in Table <a href="chapter-4.-resonance-bootstrap-random-forests.html#tab:t4-hw-rf-pred">15</a>.</p>
<p><!-- end{enumerate} --></p>
<p></p>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:t4-hw-rf-pred">Table 15: </span>Dataset for Q4</span><!--</caption>--></p>
<table>
<thead>
<tr class="header">
<th align="left">ID</th>
<th align="left"><span class="math inline">\(x_1\)</span></th>
<th align="left"><span class="math inline">\(x_2\)</span></th>
<th align="left"><span class="math inline">\(x_3\)</span></th>
<th align="left">Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(1\)</span></td>
<td align="left"><span class="math inline">\(2\)</span></td>
<td align="left"><span class="math inline">\(-0.5\)</span></td>
<td align="left"><span class="math inline">\(0.5\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(2\)</span></td>
<td align="left"><span class="math inline">\(0.8\)</span></td>
<td align="left"><span class="math inline">\(-1.1\)</span></td>
<td align="left"><span class="math inline">\(0.1\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(3\)</span></td>
<td align="left"><span class="math inline">\(1.2\)</span></td>
<td align="left"><span class="math inline">\(-0.3\)</span></td>
<td align="left"><span class="math inline">\(0.9\)</span></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p></p>
<p><!-- begin{enumerate}[resume] --></p>
<p>5. Follow up on the simulation experiment in Q9 in Chapter 2. Apply random forest with <span class="math inline">\(100\)</span> trees (by setting <code>ntree = 100</code>) on the simulated data and comment on the result.</p>
<p><!-- end{enumerate} --></p>
<!-- \begin{figure*} -->
<!--    \centering -->
<!--    \checkoddpage \ifoddpage \forcerectofloat \else \forceversofloat \fi -->
<!--    \includegraphics[width = 0.05\textwidth]{graphics/9points_4lines2.png} -->
<!-- \end{figure*} -->

</div>
</div>
<p style="text-align: center;">
<a href="chapter-3.-recognition-logistic-regression-ranking.html"><button class="btn btn-default">Previous</button></a>
<a href="chapter-5.-learning-i-cross-validation-oob.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<script src="js/jquery.js"></script>
<script src="js/tablesaw-stackonly.js"></script>
<script src="js/nudge.min.js"></script>


<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
