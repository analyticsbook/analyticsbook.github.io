---
title: "Data Analytics: A Small Data Approach"
date: "`r Sys.Date()`"
author: "Shuai Huang & Houtao Deng" # "Shuai Huang & Houtao Deng"
site: bookdown::bookdown_site
output:
  bookdown::tufte_html_book:
    split_by: chapter
    toc: yes
    toc_depth: 1
    chapter_name: 'chapter'
    template: "tufte-html-vis.html"
    tufte_variant: envisioned
    includes:
      in_header: 
        - ga_script.html
        - assets/envision-css.html
      before_body: assets/menu.html
      after_body: assets/envision-js.html

  tufte::tufte_book:
    includes:
      in_header: latex/preamble.tex
      before_body: latex/before_body.tex
      after_body: latex/after_body.tex
    keep_tex: true
    citation_package: natbib
    highlight: tango
    toc: no 
bibliography: skeleton.bib
fontfamily: mathpazo
link-citations: yes
description: This book is suitable for an introductory course of data analytics to help students understand some main statistical learning models, such as linear regression, logistic regression, tree models and random forests, ensemble learning, sparse learning, principal component analysis, kernel methods including the support vector machine and kernel regression, etc. Data science practice is a process that should be told as a story, rather than a one-time implementation of one single model. This process is a main focus of this book, with many course materials about exploratory data analysis, residual analysis, and flowcharts to develop and validate models and data pipelines.
---

```{r, echo=FALSE}
library(metathis)
meta() %>% 
  meta_description("My awesome presentation")
```

#  Cover {-}

```{r echo=FALSE, out.width="100%", fig.margin=FALSE,  fig.cap='Welcome to the online version of the Data Analytics - A Small Data Approach Book! <br><br> Code and data are available at <span style="color: blue;">[Github](https://github.com/analyticsbook/book)</span>. <br><br> Get a hard copy from <span style="color: blue;">[Amazon](https://www.amazon.com/Data-Analytics-Approach-Chapman-Science/dp/0367609509)</span>. <br><br> Contact: hello@dataanalyticsbook.info' } 
 knitr::include_graphics('graphics/cover.png',dpi = 300) 
``` 


```{r setup, include=FALSE}
library(tufte)
# install.packages("tufte_0.5.tar.gz", repos = NULL, type="source")
# R CMD build tufte
# invalidate cache when the tufte version changes
# knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
knitr::opts_chunk$set(tidy = 'formatR', tidy.opts = list(width.cutoff = 55), size = 'small', cache.extra = packageVersion('tufte'))
#options(htmltools.dir.version = FALSE)
# rmd_files: ["index.Rmd","01-intro.Rmd","02-abstraction.Rmd"]
```


# Preface {-}

<br>


```{r echo=FALSE, fig.fullwidth = TRUE, fig.align='center', fig.cap="" } 
 knitr::include_graphics('graphics/epigraph.png',dpi = 300) 
``` 

<br>

This book is suitable for an introductory course of data analytics to help students understand some main statistical learning models, such as linear regression, logistic regression, tree models and random forests, ensemble learning, sparse learning, principal component analysis, kernel methods including the support vector machine and kernel regression, etc. Data science practice is a process that should be told as a story, rather than a one-time implementation of one single model. This process is a main focus of this book, with many course materials about exploratory data analysis, residual analysis, and flowcharts to develop and validate models and data pipelines.

There are $10$ chapters. Except for Chapter 1, which gives an overview of the book, each chapter will introduce two or three techniques. For each technique, we will highlight the intuition and rationale behind it. We then articulate the intuition, use math to formulate the learning problem, and present the full version of the analytic formulation. We use R to implement the technique on both simulated or real-world datasets, present the analysis process (together with R code), show the dynamics in the analysis process, and comment on the results. Some Remarks are also made at the end of each chapter to enhance understanding of the techniques, reveal their different natures by other perspectives, reveal their limitations, and mention existing remedies to overcome these limitations.

There are three unique aspects to this book. 

First, instructors will find many small datasets (i.e., consisting of 5---10 data points of 2---4 variables) in this book for models to be manually implemented by students using step-by-step process. The idea is to let students work out pencil solutions and then compare them with results obtained from established R packages. For example, a dataset with $3$ data points and $2$ predictors is used to illustrate how the shooting algorithm of LASSO could be implemented both on paper and in the R package `glmnet`. Another example is that, to understand the concept of the support vector machine (SVM), we use a dataset with $4$ data points and $2$ predictors to illustrate how the dual formulation of SVM could be solved manually. Furthermore, by this small dataset we help students see the connection between the computational algorithm with the geometric pattern of the data, i.e., the correspondence between the numeric solution with the so-called support vectors clearly visible in the scatterplot of the data. 

Second, instructors will find graphical illustrations to explain some methods to students. These angles exploit connections between the methods; for example, the SVM is illustrated as a neural network; the kernel regression is introduced as a departure from the mindset of global models; and the logistic regression model is introduced as a few creative twists of the modeling process to apply the linear method for a binary classification problem, etc. On a larger scale, the connection between classic statistical models with machine learning algorithms is illustrated by focusing on the understanding of the iterative nature of the computational algorithms enabled by computers. We help students develop an eye for a method's connection with other models that only appear to be different. This understanding will help us know a method's strength and limitations, the importance of the context, and the assumptions we have carried in our data analysis. 

Third, it is important for students to understand the storytelling component of data science. Data scientists tell stories every day. A story conveys a message, and a skillful data scientist must have the experience that the message changes its shape and meaning, depending on which model is used, how the model is tuned, or what part of the data is used. And some models have assumed a particular storytelling mode or structure. For example, we found hypothesis testing is a difficult concept for students to understand its essence, because it is a "negative" reading of data. It is not to translate what the data says, but to seek evidence from data against the null hypothesis we will need to come up with first. Examples as such will be found in the book to help students have a larger and deeper view of what they will learn.


# Acknowledgments {-}

The first draft of this book was written in the summer of 2017 to be used as the textbook for a new course about Data Analytics (IND E 498) in the Department of Industrial & Systems Engineering of the University of Washington-Seattle. The course participants were mostly senior undergraduate students and first-year graduate students who provided invaluable comments and feedback to improve the book. The authors also thank Ameer Hamza Shakur, Jingshuo Feng, Prof. Xiangyu Chang and his students for their generous help on some figures, R code, and a range of R/LaTex tools. We also thank the Alzheimer's Disease Neuroimaging Initiative (ADNI, [https://adni.loni.usc.edu/](https://adni.loni.usc.edu/)) for the data used in this book.

In writing this book, we owe great debt to many people who generously share their materials and codes online. During the three-year writing process, we tried our best to acknowledge and cite all the specific resources we have used, and we may still have missed a few. In online communities such as [GitHub.com](GitHub.com) and [stackoverflow.com](stackoverflow.com) and numerous personal websites/blogs, you can find free resources which can help you quickly start a new project. Most importantly, this book in its current form wouldn't be possible without R and RStudio ([https://www.rstudio.com](https://www.rstudio.com)), `bookdown` ([https://bookdown.org/](https://bookdown.org/))^[Xie, Y., *Bookdown: Authoring Books and Technical Documents with R Markdown*, CRC Press, 2019.], and the Tufte-LaTeX Developers.

For the online version of the book, we are grateful to be able to leverage the components from [http://plain-text.co](https://github.com/kjhealy/plain-text.co). 

Last, but not least, the authors would like to take this opportunity to thank their editor, John Kimmel, for his support and encouragement throughout the development of this book. The authors also would like to thank the anonymous reviewers who have given great comments and the project editor Michele Dimont and the copyeditor's remarkable work to improve the book. 


