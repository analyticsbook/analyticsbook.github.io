<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Matrix Operations | Data Analytics" />
<meta property="og:type" content="book" />





<meta name="author" content="Shuai Huang &amp; Houtao Deng" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Matrix Operations | Data Analytics">

<title>Matrix Operations | Data Analytics</title>

<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<script src="https://use.typekit.net/ajy6rnl.js"></script>
<script>try{Typekit.load({ async: true });}catch(e){}</script>
<!-- <link rel="stylesheet" href="css/normalize.css"> -->
<!-- <link rel="stylesheet" href="css/envisioned.css"/> -->
<link rel="stylesheet" href="css/tablesaw-stackonly.css"/>
<link rel="stylesheet" href="css/nudge.css"/>
<link rel="stylesheet" href="css/sourcesans.css"/>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>




</head>

<body>

<!--bookdown:toc:start-->

<nav class="pushy pushy-left" id="TOC">
<ul>
<li><a href="#preface">Preface</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
<li><a href="#chapter-1.-introduction">Chapter 1. Introduction</a></li>
<li><a href="#chapter-2.-abstraction-regression-tree-models">Chapter 2. Abstraction: Regression &amp; Tree Models</a></li>
<li><a href="#chapter-3.-recognition-logistic-regression-ranking">Chapter 3. Recognition: Logistic Regression &amp; Ranking</a></li>
<li><a href="#chapter-4.-resonance-bootstrap-random-forests">Chapter 4. Resonance: Bootstrap &amp; Random Forests</a></li>
<li><a href="#chapter-5.-learning-i-cross-validation-oob">Chapter 5. Learning (I): Cross-validation &amp; OOB</a></li>
<li><a href="#chapter-6.-diagnosis-residuals-heterogeneity">Chapter 6. Diagnosis: Residuals &amp; Heterogeneity</a></li>
<li><a href="#chapter-7.-learning-ii-svm-ensemble-learning">Chapter 7. Learning (II): SVM &amp; Ensemble Learning</a></li>
<li><a href="#chapter-8.-scalability-lasso-pca">Chapter 8. Scalability: LASSO &amp; PCA</a></li>
<li><a href="#chapter-9.-pragmatism-experience-experimental">Chapter 9. Pragmatism: Experience &amp; Experimental</a></li>
<li><a href="#chapter-10.-synthesis-architecture-pipeline">Chapter 10. Synthesis: Architecture &amp; Pipeline</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#appendix-a-brief-review-of-background-knowledge">Appendix: A Brief Review of Background Knowledge</a></li>
</ul>
</nav>

<!--bookdown:toc:end-->

<div class="menu-btn"><h3>☰ Menu</h3></div>

<div class="site-overlay"></div>


<div class="row">
<div class="col-sm-12">

<nav class="pushy pushy-left" id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li><a href="chapter-1-introduction.html#chapter-1.-introduction">Chapter 1. Introduction</a></li>
<li><a href="chapter-2-abstraction-regression-tree-models.html#chapter-2.-abstraction-regression-tree-models">Chapter 2. Abstraction: Regression &amp; Tree Models</a></li>
<li><a href="chapter-3-recognition-logistic-regression-ranking.html#chapter-3.-recognition-logistic-regression-ranking">Chapter 3. Recognition: Logistic Regression &amp; Ranking</a></li>
<li><a href="chapter-4-resonance-bootstrap-random-forests.html#chapter-4.-resonance-bootstrap-random-forests">Chapter 4. Resonance: Bootstrap &amp; Random Forests</a></li>
<li><a href="chapter-5-learning-i-cross-validation-oob.html#chapter-5.-learning-i-cross-validation-oob">Chapter 5. Learning (I): Cross-validation &amp; OOB</a></li>
<li><a href="chapter-6-diagnosis-residuals-heterogeneity.html#chapter-6.-diagnosis-residuals-heterogeneity">Chapter 6. Diagnosis: Residuals &amp; Heterogeneity</a></li>
<li><a href="chapter-7-learning-ii-svm-ensemble-learning.html#chapter-7.-learning-ii-svm-ensemble-learning">Chapter 7. Learning (II): SVM &amp; Ensemble Learning</a></li>
<li><a href="chapter-8-scalability-lasso-pca.html#chapter-8.-scalability-lasso-pca">Chapter 8. Scalability: LASSO &amp; PCA</a></li>
<li><a href="chapter-9-pragmatism-experience-experimental.html#chapter-9.-pragmatism-experience-experimental">Chapter 9. Pragmatism: Experience &amp; Experimental</a></li>
<li><a href="chapter-10-synthesis-architecture-pipeline.html#chapter-10.-synthesis-architecture-pipeline">Chapter 10. Synthesis: Architecture &amp; Pipeline</a></li>
<li><a href="conclusion.html#conclusion">Conclusion</a></li>
<li><a href="appendix-a-brief-review-of-background-knowledge.html#appendix-a-brief-review-of-background-knowledge">Appendix: A Brief Review of Background Knowledge</a></li>
</ul>
</nav>

</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="matrix-operations" class="section level2 unnumbered">
<h2>Matrix Operations</h2>
<p>A matrix is a basic structure in data analytics that organizes data in a rectangular array, e.g., a matrix <span class="math inline">\(\boldsymbol{X} \in R^{p \times q}\)</span> with <span class="math inline">\(p\)</span> rows and <span class="math inline">\(q\)</span> columns is</p>
<p><span class="math display">\[
\boldsymbol{X}=\left[ \begin{array}{cccc} {x_{11}} &amp; {x_{12}} &amp; {\cdots} &amp; {x_{1q}} \\ {x_{21}} &amp; {x_{22}} &amp; {\cdots} &amp; {x_{2q}} \\ {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots} \\ {x_{p1}} &amp; {x_{p2}} &amp; {\cdots} &amp; {x_{pq}}\end{array}\right].
\]</span></p>
<p><em>Matrix transposition.</em> A matrix <span class="math inline">\(\boldsymbol{X} \in R^{p \times q}\)</span> could be transposed into a matrix <span class="math inline">\(\boldsymbol{X}^T \in R^{q \times p}\)</span>, i.e.,</p>
<p><span class="math display">\[
\boldsymbol{X}^T=\left[ \begin{array}{cccc} {x_{11}} &amp; {x_{21}} &amp; {\cdots} &amp; {x_{q1}} \\ {x_{12}} &amp; {x_{22}} &amp; {\cdots} &amp; {x_{q2}} \\ {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots} \\ {x_{1p}} &amp; {x_{2p}} &amp; {\cdots} &amp; {x_{qp}}\end{array}\right].
\]</span></p>
<p><em>Matrix addition.</em> Two matrices of the same dimensions could be added together entrywise, i.e., <span class="math inline">\(\boldsymbol{X} + \boldsymbol{Y}\)</span> is defined as</p>
<p><span class="math display">\[
\boldsymbol{X + Y}=\left[ \begin{array}{cccc} {x_{11}+y_{11}} &amp; {x_{12}+y_{12}} &amp; {\cdots} &amp; {x_{1q}+y_{1q}} \\ {x_{21}+y_{21}} &amp; {x_{22}+y_{22}} &amp; {\cdots} &amp; {x_{2q}+y_{2q}} \\ {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots} \\ {x_{p1}+y_{p1}} &amp; {x_{p2}+y_{p2}} &amp; {\cdots} &amp; {x_{pq}+y_{pq}}\end{array}\right].
\]</span></p>
<p><em>Scalar multiplication:</em> The product of a constant <span class="math inline">\(c\)</span> and a matrix <span class="math inline">\(\boldsymbol{X} \in R^{p \times q}\)</span> is computed by multiplying every entry of <span class="math inline">\(\boldsymbol{X} \in R^{p \times q}\)</span> by <span class="math inline">\(c\)</span>, i.e.,</p>
<p><span class="math display">\[
c\boldsymbol{X}=\left[ \begin{array}{cccc} {cx_{11}} &amp; {cx_{12}} &amp; {\cdots} &amp; {cx_{1q}} \\ {cx_{21}} &amp; {cx_{22}} &amp; {\cdots} &amp; {cx_{2q}} \\ {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots} \\ {cx_{p1}} &amp; {cx_{p2}} &amp; {\cdots} &amp; {cx_{pq}}\end{array}\right].
\]</span></p>
<p><em>Matrix multiplication.</em> Two matrices could be multiplied if the number of columns of the left matrix is the same as the number of rows of the right matrix, i.e., for <span class="math inline">\(\boldsymbol{X} \in R^{p \times q}\)</span>, it could be multiplied with any matrix that has <span class="math inline">\(q\)</span> rows. Let’s say we have two matrices, <span class="math inline">\(\boldsymbol{X} \in R^{2 \times 3}\)</span> and <span class="math inline">\(\boldsymbol{Y} \in R^{3 \times 2}\)</span>, the multiplication <span class="math inline">\(\boldsymbol{XY}\)</span> is a matrix <span class="math inline">\(\in R^{2 \times 2}\)</span>, where</p>
<p><span class="math display">\[
\boldsymbol{XY}=\left[ \begin{array}{cccc} {x_{11}y_{11}+ x_{12}y_{21}+ x_{13}y_{31}}  &amp; {x_{11}y_{12}+ x_{12}y_{22}+ x_{13}y_{32}} \\ {x_{21}y_{11}+ x_{22}y_{21}+ x_{23}y_{31}} &amp; {x_{21}y_{12}+ x_{22}y_{22}+ x_{23}y_{32}}\end{array}\right].
\]</span></p>
<p><em>Matrix derivative.</em> Matrix derivative is a rich category that includes many situations. Readers may find a comprehensive coverage in a few books<label for="tufte-sn-283" class="margin-toggle sidenote-number">283</label><input type="checkbox" id="tufte-sn-283" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">283</span> Harville, D.A., <em>Matrix Algebra From a Statistician’s Perspective</em>, Springer, 2000.</span> or find a quick reference in online resources<label for="tufte-sn-284" class="margin-toggle sidenote-number">284</label><input type="checkbox" id="tufte-sn-284" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">284</span> Petersen, K.B. and
Pedersen, M.S., <em>The Matrix Cookbook</em>, online document (<a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf">https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf</a>).</span>. Here, we mention a few examples that are related topics in this book.</p>
<p>Denote that <span class="math inline">\(y=f(\boldsymbol{X})\)</span> is a scalar function of the matrix <span class="math inline">\(\boldsymbol{X} \in R^{p \times q}\)</span>. Then derivative of <span class="math inline">\(y\)</span> with respect to the matrix <span class="math inline">\(\boldsymbol{X}\)</span> is given by</p>
<p><span class="math display">\[
\frac{\partial y }{\partial \boldsymbol{X}} = \left[ \begin{array}{cccc} \frac{\partial y }{\partial x_{11}} &amp; \frac{\partial y }{\partial x_{12}} &amp; {\cdots} &amp; \frac{\partial y }{\partial x_{1q}} \\ \frac{\partial y }{\partial x_{21}} &amp; \frac{\partial y }{\partial x_{22}} &amp; {\cdots} &amp; \frac{\partial y }{\partial x_{2q}} \\ {\vdots} &amp; {\vdots} &amp; {\vdots} &amp; {\vdots} \\ \frac{\partial y }{\partial x_{p1}} &amp; \frac{\partial y }{\partial x_{p2}} &amp; {\cdots} &amp; \frac{\partial y }{\partial x_{pq}}\end{array}\right].
\]</span></p>
<p>Based on this definition, we can derive that</p>
<p><span class="math display">\[
\frac{\partial \boldsymbol{a}^T\boldsymbol{x} }{\partial \boldsymbol{x}} = \boldsymbol{a};
\]</span></p>
<p><span class="math display">\[
\frac{\partial \boldsymbol{x}^T\boldsymbol{B}\boldsymbol{x} }{\partial \boldsymbol{x}} = (\boldsymbol{B} + \boldsymbol{B}^T)\boldsymbol{x};
\]</span></p>
<p><span class="math display">\[
\frac{\partial \boldsymbol{(x-a)}^T\boldsymbol{B}\boldsymbol{(x-a)} }{\partial \boldsymbol{x}} = 2\boldsymbol{B}\boldsymbol{(x-a)};
\]</span></p>
<p><span class="math display">\[
\frac{\partial \boldsymbol{(Ax+b)}^T\boldsymbol{W}\boldsymbol{(Cx+d)} }{\partial \boldsymbol{x}} = \boldsymbol{A}^T\boldsymbol{W}\boldsymbol{(Cx+d)} + \boldsymbol{C}^T\boldsymbol{W}\boldsymbol{(Ax+b)}.
\]</span></p>
<p><em>Matrix norm.</em> The <span class="math inline">\(L_1\)</span> norm of a vector <span class="math inline">\(\boldsymbol{x}\)</span> is defined as</p>
<p><span class="math display">\[
\lVert \boldsymbol{x} \rVert_1 = \sum_{i=1}^p \lvert x_i \rvert.
\]</span></p>
<p>The <span class="math inline">\(L_2\)</span> norm of a vector <span class="math inline">\(\boldsymbol{x}\)</span> is defined as</p>
<p><span class="math display">\[
\lVert \boldsymbol{x} \rVert^2_2 = \sum_{i=1}^p x_i^2.
\]</span></p>
</div>
<p style="text-align: center;">
<a href="the-normal-distribution.html"><button class="btn btn-default">Previous</button></a>
<a href="optimization.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>

<script src="js/jquery.js"></script>
<script src="js/tablesaw-stackonly.js"></script>
<script src="js/nudge.min.js"></script>


<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
